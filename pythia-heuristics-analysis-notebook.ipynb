{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics analysis across training notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains random code for analyzing the models across training checkpoints.\n",
    "\n",
    "The code here is more messy, and shouldn't be referenced to. \n",
    "\n",
    "The code focuses on Pythia-6.9B, and contains initial experimentations (analyzed further in ``script_analyze_model_heursitics.py``) as well as the visualizations shown in section 5 in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from general_utils import set_deterministic, set_cuda_device\n",
    "set_cuda_device(0)\n",
    "\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import transformer_lens as lens\n",
    "import re\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from fancy_einsum import einsum\n",
    "from pprint import pprint\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import GPTNeoXForCausalLM\n",
    "from prompt_generation import generate_all_prompts_for_operator, OPERATORS, OPERATOR_NAMES, _is_number, _maximize_unique_answers\n",
    "from visualization_utils import line, imshow, multiple_lines\n",
    "from general_utils import generate_activations, set_deterministic\n",
    "from evaluation_utils import model_accuracy, circuit_faithfulness_with_mean_ablation\n",
    "from model_analysis_consts import PYTHIA_6_9B_CONSTS\n",
    "from heuristics_classification import load_heuristic_classes\n",
    "from script_analyze_model_heuristics import HEURISTIC_MATCH_THRESHOLD\n",
    "from component import Component\n",
    "from script_eval_pythia_faithfulness_only_mutual_neurons import build_circuit, get_heuristic_neurons, get_intersection_neurons\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = 'cuda'\n",
    "seed = 42\n",
    "PYTHIA_PREFIX = \"pythia-6.9b\"\n",
    "\n",
    "COLORBLIND_COLORS = ['#0173b2', '#de8f05', '#029e73','#d55e00', '#cc78bc', '#ca9161', '#fbafe4', '#949494', '#ece133', '#56b4e9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions, similar to those defined in the main notebook\n",
    "\n",
    "def reverse_heuristic_dictionary(d):\n",
    "    result = {}\n",
    "    for heuristic, layer_neuron_scores in d.items():\n",
    "        for lns in layer_neuron_scores:\n",
    "            result.setdefault(lns[:2], []).append((heuristic, lns[2]))\n",
    "    return result\n",
    "\n",
    "def _get_top_op1_op2_indices(layer, neuron_idx, prompts_activations, top_k=None, is_top=True):\n",
    "    activation_map = prompts_activations[(layer, neuron_idx)]\n",
    "    if top_k is None:\n",
    "        top_k = len(activation_map)\n",
    "    top_op1_op2_pairs = op1_op2_pairs[activation_map.topk(top_k, largest=is_top).indices.cpu().numpy()].tolist()\n",
    "    return top_op1_op2_pairs\n",
    "\n",
    "def present_neuron(layer, neuron, use_kv_maps=True):\n",
    "    if use_kv_maps:\n",
    "        prompts_activations = kv_prompts_activations\n",
    "    else:\n",
    "        prompts_activations = k_prompts_activations\n",
    "    v_tokens = 10\n",
    "    vector_logits = model.blocks[layer].mlp.W_out[neuron] @ model.W_U\n",
    "    topk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[arithmetic_tokens].view(-1).topk(v_tokens).indices], prepend_bos=False)\n",
    "    bottomk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[arithmetic_tokens].view(-1).topk(v_tokens, largest=False).indices], prepend_bos=False)\n",
    "    print(f'Neuron {neuron} logit lens:')    \n",
    "    activation_img = torch.zeros((max_op - min_op, max_op - min_op))\n",
    "    for i, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "        activation_img[op1 - min_op, op2 - min_op] = prompts_activations[(layer, neuron)][i]\n",
    "\n",
    "    imshow(activation_img, x=list(range(min_op, max_op)), y=list(range(min_op, max_op)), labels={'x': 'Operand2', 'y': 'Operand1'}, width=600,\n",
    "        title=f'Neuron {neuron} activations in MLP {layer} as function of operands')\n",
    "    topk_op1_op2_pairs, bottomk_op1_op2_pairs =  _get_top_op1_op2_indices(layer, neuron, prompts_activations, top_k=50), \\\n",
    "                                                 _get_top_op1_op2_indices(layer, neuron, prompts_activations, top_k=50, is_top=False)\n",
    "    print(\"Top 50 op1,op2 values in activation map: \", topk_op1_op2_pairs)\n",
    "    print(\"Top results: \", [simple_eval(f\"{op1}{OPERATORS[operator_idx]}{op2}\") for (op1, op2) in topk_op1_op2_pairs])\n",
    "    if not use_kv_maps:\n",
    "        print(f'Top arithmetic {v_tokens} tokens: {topk_arithmetic_tokens}')\n",
    "    print(sorted(rev_heuristic_classes[(layer, neuron)], key=lambda x:x[1], reverse=True))\n",
    "\n",
    "\n",
    "def _get_neuron_importance_scores_across_operators(model_name):\n",
    "    \"\"\"\n",
    "    Get a unified list of top neurons across operators.\n",
    "    \"\"\"\n",
    "    all_neuron_scores = [_get_neuron_importance_scores(model_name, op_idx, use_2shot_prompting=False) for op_idx in range(len(OPERATORS))]\n",
    "    mean_neuron_scores = {layer: sum([neuron_scores[layer] for neuron_scores in all_neuron_scores]) / len(OPERATORS) for layer in range(0, 32)}\n",
    "    return mean_neuron_scores\n",
    "\n",
    "\n",
    "def _get_neuron_importance_scores(model_name, operator_idx, use_2shot_prompting):\n",
    "    \"\"\"\n",
    "    Override of function in general_utils to support 2shot prompting experimentation\n",
    "    \"\"\"\n",
    "    def ranking_func(attribution_scores, pos):\n",
    "        return attribution_scores[:, pos].mean(dim=0) + attribution_scores[:, pos].std(dim=0)\n",
    "        \n",
    "    neuron_attribution_scores = torch.load(f\"./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_node_attribution_scores{'_with_2shot_prompting' if use_2shot_prompting else ''}.pt\")\n",
    "    neurons_scores = {layer: ranking_func(neuron_attribution_scores[f'blocks.{layer}.mlp.hook_post'], pos=-1) for layer in range(0, 32)}\n",
    "    return neurons_scores\n",
    "    \n",
    "\n",
    "def find_all_pythia_steps():\n",
    "    \"\"\"\n",
    "    Find all analyzed training checkpoint names in the Pythia 6.9b data directory.\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    for file in os.listdir('./data/'):\n",
    "        if PYTHIA_PREFIX in file and PYTHIA_PREFIX != file:\n",
    "            step = int(file.split(PYTHIA_PREFIX + \"-step\")[1])\n",
    "            steps.append(step)\n",
    "    return sorted(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure model accuracy\n",
    "\n",
    "model_name = \"pythia-6.9b-step143000\"\n",
    "results_dir = f\"./data/{model_name}/\"\n",
    "\n",
    "with open(os.path.join(results_dir, f'large_prompts_and_answers_max_op=300.pkl'), \"rb\") as f:\n",
    "    large_prompts_and_answers = pickle.load(f)\n",
    "pprint(large_prompts_and_answers[0])\n",
    "pprint(large_prompts_and_answers[1])\n",
    "\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    op = OPERATORS[operator_idx]\n",
    "    print(op)\n",
    "    print(\"Model accuracy: \", torch.load(os.path.join(results_dir, 'accuracy.pt'))[op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many prompts completed correctly by the model are \"junk\" prompts (for example, completed using simple copy mechanisms when the result is equal to one of the operands)?\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - set([3000, 13000]))\n",
    "\n",
    "for step in steps:\n",
    "    model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "    large_prompts_and_answers = pickle.load(open( fr'./data/{model_name}/large_prompts_and_answers_max_op=300.pkl', 'rb'))\n",
    "    for operator_idx in range(len(OPERATORS)):\n",
    "        junk_count = 0\n",
    "        for (prompt, answer) in large_prompts_and_answers[operator_idx]:\n",
    "            answer = int(answer)\n",
    "            op1, op2 = list(map(int, prompt[:-1].split(OPERATORS[operator_idx])))\n",
    "            if answer == 0 or answer == 1:\n",
    "                junk_count += 1\n",
    "            elif op1 == 0 or op2 == 0 or op1 == 1 or op2 == 1:\n",
    "                junk_count += 1\n",
    "            else:\n",
    "                pass\n",
    "        print(f\"{step=}, {OPERATORS[operator_idx]}: {junk_count/len(large_prompts_and_answers[operator_idx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at correctly completed prompts for a specific training checkpoint\n",
    "\n",
    "def load_prompts(model_name):\n",
    "    analysis_prompts_file_path = fr'./data/{model_name}/large_prompts_and_answers_max_op=300.pkl'\n",
    "    with open(analysis_prompts_file_path, 'rb') as f:\n",
    "        large_prompts_and_answers = pickle.load(f)\n",
    "\n",
    "    set_deterministic(42)\n",
    "    wanted_size = 50\n",
    "    filtered_prompts_and_answers = []\n",
    "    for i, pa in enumerate(large_prompts_and_answers):\n",
    "        new_pa = []\n",
    "        for p, a in pa:\n",
    "            # Filter out simple prompts (x/0, x*1, etc)\n",
    "            op1, op2 = tuple(map(int, re.findall(r'\\d+', p)))[-2:]\n",
    "            if op1 > 5 and op2 > 5 and int(a) > 2:\n",
    "                new_pa.append((p, a))\n",
    "        if len(new_pa) < wanted_size:\n",
    "            print(len(new_pa), f' length of new_pa for operator {i}')\n",
    "            new_pa = new_pa + random.sample(pa, k=wanted_size - len(new_pa))\n",
    "        filtered_prompts_and_answers.append(new_pa)\n",
    "    correct_prompts_and_answers = [_maximize_unique_answers(pa, k=wanted_size) for pa in filtered_prompts_and_answers]\n",
    "    return large_prompts_and_answers, correct_prompts_and_answers\n",
    "\n",
    "large, correct = load_prompts(f'{PYTHIA_PREFIX}-step143000')\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present model accuracy across timesteps\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000}) # Remove too early checkpoints (where the model doesn't really solve arithmetics with a non-random mechanism) and the extra test checkpoints at the end\n",
    "accuracies = [[torch.load(os.path.join('./data', f'{PYTHIA_PREFIX}-step{step}', 'accuracy.pt'))[op] for step in steps] for op in OPERATORS]\n",
    "multiple_lines(x=steps, y=torch.tensor(accuracies), line_titles=OPERATORS, width=400)\n",
    "line(torch.tensor(accuracies).mean(dim=0), x=steps, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many heuristics neurons are shared between each timestep?\n",
    "\n",
    "threshold = 0.001\n",
    "topk_neuron_per_layer = 50\n",
    "use_threshold = False\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "print(steps)\n",
    "shared_neurons_iou = torch.zeros((len(steps), len(steps)))\n",
    "\n",
    "neuron_scores = {step: _get_neuron_importance_scores_across_operators(f\"{PYTHIA_PREFIX}-step{step}\") for step in steps} # Caching for faster calculations\n",
    "# neuron_scores = {step: _get_neuron_importance_scores(f\"{PYTHIA_PREFIX}-step{step}\", operator_idx=0, use_2shot_prompting=False) for step in steps}\n",
    "\n",
    "for layers_to_analyze in [list(range(PYTHIA_6_9B_CONSTS.first_heuristics_layer, 32))]:\n",
    "    print(layers_to_analyze)\n",
    "    for i in range(len(steps)):\n",
    "        for j in tqdm(range(i, len(steps))):\n",
    "            try:\n",
    "                neuron_scores_i = neuron_scores[steps[i]]\n",
    "                neuron_scores_j = neuron_scores[steps[j]]\n",
    "                if use_threshold:\n",
    "                    heuristic_neurons_i = set(sum([[(layer, neuron) for neuron in (neuron_scores_i[layer] > threshold).nonzero().view(-1).tolist()] for layer in layers_to_analyze], []))\n",
    "                    heuristic_neurons_j = set(sum([[(layer, neuron) for neuron in (neuron_scores_j[layer] > threshold).nonzero().view(-1).tolist()] for layer in layers_to_analyze], []))\n",
    "                    shared_neurons_iou[i, j] = len(heuristic_neurons_i.intersection(heuristic_neurons_j)) / len(heuristic_neurons_i.union(heuristic_neurons_j))\n",
    "                else:\n",
    "                    heuristic_neurons_i = set(sum([[(layer, neuron) for neuron in neuron_scores_i[layer].topk(topk_neuron_per_layer).indices.tolist()] for layer in layers_to_analyze], []))\n",
    "                    heuristic_neurons_j = set(sum([[(layer, neuron) for neuron in neuron_scores_j[layer].topk(topk_neuron_per_layer).indices.tolist()] for layer in layers_to_analyze], []))\n",
    "                    shared_neurons_iou[i, j] = len(heuristic_neurons_i.intersection(heuristic_neurons_j)) / len(heuristic_neurons_i)\n",
    "                shared_neurons_iou[j, i] = shared_neurons_iou[i, j]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                shared_neurons_iou[i, j] = 0.0\n",
    "                \n",
    "    px.imshow(shared_neurons_iou, width=500, x=steps, y=steps, zmin=0.0, zmax=1.0, labels={'x': 'Step', 'y': 'Step'}, title=f'Shared Neurons between Steps', color_continuous_scale=\"blues\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph of the mean clean and mean ablated accs across operators and averaged across operators\n",
    "\n",
    "def get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting=False):\n",
    "    try:\n",
    "        model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "        heuristics_knockout_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}_thres={match_threshold}_{knockout_map_type}_maps.pt')\n",
    "        heuristics_knockout_results = [h for h in heuristics_knockout_results if \\\n",
    "                                        len(h.ablated_neurons)>= MIN_NEURONS_PER_HEURISTIC and \n",
    "                                        h.ablated_neuron_matching_score >= MIN_SCORE_SUM_PER_HEURISTIC]\n",
    "        if knockout_map_type == \"KV\":\n",
    "            # No point in looking at operand heuristics\n",
    "            heuristics_knockout_results = [h for h in heuristics_knockout_results if h.heuristic_name.startswith('result')]\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e}\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    baseline_related = torch.tensor([h.baseline_related for h in heuristics_knockout_results])\n",
    "    ablated_related = torch.tensor([h.ablated_related for h in heuristics_knockout_results])\n",
    "    return baseline_related.mean().item(), ablated_related.mean().item()\n",
    "\n",
    "match_threshold = 0.6\n",
    "MIN_NEURONS_PER_HEURISTIC = 20.0\n",
    "MIN_SCORE_SUM_PER_HEURISTIC = 20.0\n",
    "knockout_map_type = [\"KV\", \"K\", \"HYBRID\"][2]\n",
    "use_2shot_prompting = False\n",
    "operators_to_process = range(len(OPERATORS))\n",
    "\n",
    "accs_per_step = []\n",
    "ablated_accs_per_step = []\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "for operator_idx in operators_to_process:\n",
    "    accs_per_step.append([get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting)[0] for step in steps])\n",
    "    ablated_accs_per_step.append([get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting)[1] for step in steps])\n",
    "\n",
    "lines = []\n",
    "line_titles = []\n",
    "colors = []\n",
    "for i in operators_to_process:\n",
    "    lines.extend([accs_per_step[i], ablated_accs_per_step[i]])\n",
    "    line_titles.extend([f\"Pre-ablation {OPERATORS[i]}\", f\"Post-ablation {OPERATORS[i]}\"])\n",
    "lines.extend([torch.tensor(accs_per_step[:2]).mean(dim=0).tolist(), \n",
    "              torch.tensor(ablated_accs_per_step[:2]).mean(dim=0).tolist()])\n",
    "line_titles.extend([f\"Pre-ablation mean\", f\"Post-ablation mean\"])\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "multiple_lines(y=lines, x=steps, line_titles=line_titles,\n",
    "        title=f'Heuristic knockout accuracies <br>(Clean & Mean over heuristic ablations) <br>over training steps',\n",
    "        xaxis_title=\"Training step\",\n",
    "        yaxis_title=\"Accuracy\",\n",
    "        yaxis=dict(range=(0.0, 1.0)),\n",
    "        height=400,\n",
    "        width=500)\n",
    "\n",
    "avg_corr = 0\n",
    "for op_idx in range(len(OPERATORS)):\n",
    "    knockout_diff_per_step = [accs_per_step[op_idx][i] - ablated_accs_per_step[op_idx][i] for i in range(len(steps))]\n",
    "    corr = pearsonr(accs_per_step[op_idx], knockout_diff_per_step)[0]\n",
    "    print(f\"{op_idx=}, Correlation of acc to knockout diff: {corr}\")\n",
    "    avg_corr += corr\n",
    "avg_corr /= len(OPERATORS)\n",
    "print(f\"{avg_corr=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the heuristic statistics as function of training steps\n",
    "\n",
    "THRESHOLD = 0.6\n",
    "OPERATORS_TO_ANALYZE = range(len(OPERATORS))\n",
    "knockout_type = \"HYBRID\"\n",
    "use_2shot_prompting = False\n",
    "k_neuron_filter = 50 # How many topk neurons (per layer) to consider (Only allow heuristic matches of these neurons)\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "heuristic_category_patterns = [r\"op\\d_\\d+mod\\d+\", r\"result_\\d+mod\\d+\", \n",
    "                            r\"op\\d_region_\\d+_\\d+\", r\"result_region_\\d+_\\d+\", \n",
    "                            r\"op\\d_value_\\d+\", r\"result_value_\\d+\", \n",
    "                            r\"op\\d_pattern_.*\", r\"result_pattern_.*\"]\n",
    "heuristic_counts_across_steps = torch.zeros((len(heuristic_category_patterns), len(steps), len(OPERATORS_TO_ANALYZE)))\n",
    "\n",
    "\n",
    "for operator_idx in OPERATORS_TO_ANALYZE:\n",
    "    for step_idx in range(len(steps)):\n",
    "        model_name = f\"{PYTHIA_PREFIX}-step{steps[step_idx]}\"\n",
    "        try:\n",
    "            heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", \n",
    "                                                    operator_idx, knockout_type, \n",
    "                                                    override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}')\n",
    "            heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    "\n",
    "            # Filter only top-k neurons\n",
    "            neuron_scores = _get_neuron_importance_scores_across_operators(model_name)\n",
    "            top_neurons_of_model = {layer: neuron_scores[layer].topk(k_neuron_filter).indices.tolist() for layer in neuron_scores.keys()}\n",
    "            heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if n in top_neurons_of_model[l]] for name, layer_neuron_scores in heuristic_classes.items()}\n",
    "\n",
    "            # Unify the heuristic classes according to pattern\n",
    "            unified_heuristic_classes = {}\n",
    "            for pattern in heuristic_category_patterns:\n",
    "                pattern_keys = [key for key in heuristic_classes.keys() if re.search(pattern, key)]\n",
    "                unified_heuristic_classes[pattern] = sum([heuristic_classes[key] for key in pattern_keys], [])\n",
    "                \n",
    "                # Remove duplicates (layer, neuron) pairs\n",
    "                unified_heuristic_classes[pattern] = list(set([(l, n) for (l, n, s) in unified_heuristic_classes[pattern]]))\n",
    "\n",
    "            # Count the neuron in each heuristic\n",
    "            for i, pattern in enumerate(heuristic_category_patterns):\n",
    "                heuristic_counts_across_steps[i, step_idx, operator_idx] = len(unified_heuristic_classes[pattern])\n",
    "        except:\n",
    "            for i, pattern in enumerate(heuristic_category_patterns):\n",
    "                heuristic_counts_across_steps[i, step_idx, operator_idx] = 0.0\n",
    "        \n",
    "\n",
    "for op_idx in range(len(OPERATORS_TO_ANALYZE)):\n",
    "    fig = multiple_lines(y=heuristic_counts_across_steps[:, :, op_idx], x=steps, line_titles=heuristic_category_patterns,\n",
    "        title=f'Neurons per heuristic category over training steps<br>({OPERATOR_NAMES[op_idx]})',\n",
    "        xaxis_title=\"Training step\",\n",
    "        yaxis_title=\"Neurons count\",\n",
    "        width=500,\n",
    "        show_fig=False)\n",
    "    fig.show()\n",
    "\n",
    "# Average across operators \n",
    "multiple_lines(y=heuristic_counts_across_steps.mean(dim=2), x=steps, line_titles=heuristic_category_patterns,\n",
    "        title=f'Neurons per heuristic category over training steps<br>(Averaged across operators)',\n",
    "        xaxis_title=\"Training step\",\n",
    "        yaxis_title=\"Neurons count\",\n",
    "        width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the heuristics intersection with a chosen training step (without categorization, weighted mean across all heuristics)\n",
    "\n",
    "def get_heuristics_that_appear_across_all_steps(operator_idx, steps):\n",
    "    a = set(load_heuristic_classes(f\"./data/pythia-6.9b-step143000\", operator_idx, knockout_type, override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}').keys())\n",
    "    for step in steps:\n",
    "        b = set(load_heuristic_classes(f\"./data/pythia-6.9b-step{step}\", operator_idx, knockout_type, override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}').keys())\n",
    "        a = a.intersection(b)\n",
    "    return a\n",
    "\n",
    "\n",
    "THRESHOLD = 0.6\n",
    "knockout_type = \"HYBRID\"\n",
    "use_2shot_prompting = False\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(list(set(steps) - {3000, 13000}))\n",
    "print(steps)\n",
    "\n",
    "mean_heuristic_intersections = torch.zeros((len(OPERATORS), len(steps)))\n",
    "step_idx_to_compare_to = steps.index(143000)\n",
    "gt_model_name = f\"{PYTHIA_PREFIX}-step{steps[step_idx_to_compare_to]}\"\n",
    "\n",
    "intersection_neurons = {}\n",
    "\n",
    "print(f\"Comparing to step {steps[step_idx_to_compare_to]}\")\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    gt_heuristic_classes = load_heuristic_classes(f\"./data/{gt_model_name}\", operator_idx, knockout_type, override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}')\n",
    "    print('0', len(gt_heuristic_classes.keys()))\n",
    "    \n",
    "    # Filter by threshold\n",
    "    gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}\n",
    "    print('1', len(gt_heuristic_classes.keys()))\n",
    "\n",
    "    # Filter only top-k neurons\n",
    "    k = 200\n",
    "    neuron_scores = _get_neuron_importance_scores(gt_model_name, operator_idx, use_2shot_prompting)\n",
    "    top_neuron_of_model = {layer: neuron_scores[layer].topk(k).indices.tolist() for layer in neuron_scores.keys()}\n",
    "    gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if n in top_neuron_of_model[l]] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}\n",
    "    print('2', len(gt_heuristic_classes.keys()))\n",
    "\n",
    "    # Filter only heuristics that appear in all training steps\n",
    "    gt_heuristic_names = get_heuristics_that_appear_across_all_steps(operator_idx, steps)\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if name in gt_heuristic_names}\n",
    "    print('3', len(gt_heuristic_classes.keys()))\n",
    "\n",
    "    gt_heuristic_names = sorted(gt_heuristic_classes.keys())\n",
    "    heuristic_intersections = torch.zeros(len(gt_heuristic_names), len(steps))\n",
    "    for step_idx, step in enumerate(steps):\n",
    "        model_name = f\"{PYTHIA_PREFIX}-step{steps[step_idx]}\"\n",
    "        heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", \n",
    "                                                    operator_idx, knockout_type, \n",
    "                                                    override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}')\n",
    "        heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    " \n",
    "        for heuristic_idx, heuristic_name in enumerate(gt_heuristic_names):\n",
    "            gt_neurons = set([(l, n) for (l, n, s) in gt_heuristic_classes[heuristic_name]])\n",
    "            neurons = set([(l, n) for (l, n, s) in heuristic_classes[heuristic_name]])\n",
    "            intersection_neurons[(operator_idx, heuristic_name, step)] = neurons.intersection(gt_neurons)\n",
    "            heuristic_intersections[heuristic_idx, step_idx] = len(neurons.intersection(gt_neurons)) / len(gt_neurons)\n",
    "\n",
    "    mean_heuristic_intersections[operator_idx, :] = heuristic_intersections.mean(dim=0)\n",
    "\n",
    "fig = multiple_lines(y=mean_heuristic_intersections, x=steps, line_titles=OPERATORS,\n",
    "        title=f'Heuristic neuron intersection between steps',\n",
    "        xaxis_title=\"Training step\",\n",
    "        yaxis_title=\"Intersection ratio\",\n",
    "        width=1000,\n",
    "        height=300,\n",
    "        show_fig=False)\n",
    "fig.update_layout(\n",
    "    yaxis_range=[0.0, 1.0]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the heuristic list in the last (GT) checkpoint\n",
    "HEURISTIC_THRESHOLD = 0.6\n",
    "step_to_compare_to = \"143000\"\n",
    "gt_model_name = f\"{PYTHIA_PREFIX}-step{step_to_compare_to}\"\n",
    "model_name = f\"{PYTHIA_PREFIX}-step142000\"\n",
    "\n",
    "gt_heuristic_classes = load_heuristic_classes(f\"./data/{gt_model_name}\", operator_idx, \"HYBRID\")\n",
    "# Filter by threshold\n",
    "gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= HEURISTIC_THRESHOLD] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}    \n",
    "gt_heuristic_neuron_pairs = [(h_name, l, n) for h_name, lns in gt_heuristic_classes.items() for (l, n, s) in lns]\n",
    "\n",
    "# Generate the heuristic list in the current model\n",
    "heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", operator_idx, \"HYBRID\")\n",
    "# Filter by threshold\n",
    "heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= HEURISTIC_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()}\n",
    "heuristic_classes = {name: lns for name, lns in heuristic_classes.items() if len(lns) > 0}\n",
    "heuristic_neuron_pairs = [(h_name, l, n) for h_name, lns in heuristic_classes.items() for (l, n, s) in lns]\n",
    "\n",
    "# Get the intersection of the neurons\n",
    "mutual_neurons = list(set([(l, n) for (h_name, l, n) in set(gt_heuristic_neuron_pairs).intersection(set(heuristic_neuron_pairs))]))\n",
    "mutual_neurons = {layer: [n for (l, n) in mutual_neurons if l == layer] for layer in range(32)}\n",
    "print(len(list(chain.from_iterable(mutual_neurons.values()))))\n",
    "print(mutual_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate faithfulness with all top-200 neurons and only with those that intersect with the last checkpoint \n",
    "\n",
    "# How many neurons are shared between each timestep?\n",
    "operator_idx = 0\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "\n",
    "for step in steps:\n",
    "    model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "    heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", operator_idx, knockout_type)\n",
    "    heuristic_neurons = set([(v[0], v[1]) for v in chain.from_iterable(heuristic_classes.values())])\n",
    "    print(step, 'Pre-filtering', len(heuristic_neurons))\n",
    "    \n",
    "    # Filter by threshold\n",
    "    heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()}\n",
    "    heuristic_classes = {name: lns for name, lns in heuristic_classes.items() if len(lns) > 0}\n",
    "    heuristic_neurons = set([(v[0], v[1]) for v in chain.from_iterable(heuristic_classes.values())])\n",
    "    print(step, 'Post-threshold-filtering', len(heuristic_neurons))\n",
    "\n",
    "    print(step, len(set(chain.from_iterable([v for k, v in intersection_neurons.items() if k[0] == operator_idx and k[2] == step]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the prompt knockout score as a func of training steps\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(list(set(steps) - {3000, 13000}))\n",
    "colors = ['lightblue', 'cadetblue', 'darkblue', 'midnightblue']\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[steps[0], steps[-1]], y=[1, 1], mode='lines', name='Baseline', line=dict(color='black')))\n",
    "\n",
    "for i, chosen_neuron_hard_limit in enumerate([5, 25, 50]):\n",
    "    ablated_results_per_step = torch.zeros((len(OPERATORS), len(steps)))\n",
    "    control_results_per_step = torch.zeros((len(OPERATORS), len(steps)))\n",
    "\n",
    "    # Collect the data to present from the files\n",
    "    for operator_idx in range(len(OPERATORS)):\n",
    "        for step_idx, step in enumerate(steps):\n",
    "            model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "            neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_prompt_ablation_results_thres=0.6_HYBRID_maps.pt')\n",
    "            assert torch.all(baseline_results == 1)\n",
    "\n",
    "            chosen_neuron_hard_limit_idx = list(neuron_hard_limits).index(chosen_neuron_hard_limit)\n",
    "            ablated_results_per_step[operator_idx, step_idx] = ablated_results[chosen_neuron_hard_limit_idx]\n",
    "            control_results_per_step[operator_idx, step_idx] = control_results[chosen_neuron_hard_limit_idx]\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=steps, y=ablated_results_per_step[:2].mean(dim=0), mode='lines', name=f'Mean (ablated, neurons={chosen_neuron_hard_limit})', line=dict(color=colors[i])))\n",
    "    fig.add_trace(go.Scatter(x=steps, y=control_results_per_step.mean(dim=0), mode='lines', name=f'Mean (control, neurons={chosen_neuron_hard_limit})', line=dict(color=colors[i], dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Ablated and Control Accuracies',\n",
    "    xaxis_title=f'Ablated Neurons (Per Layer)',\n",
    "    yaxis_title='Accuracy',\n",
    "    legend_title='',\n",
    "    width=700,\n",
    "    yaxis_range=[0.0, 1.02],\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph of the mean clean and mean ablated accs across operators and averaged across operators\n",
    "\n",
    "def get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting=False):\n",
    "    try:\n",
    "        model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "        heuristics_knockout_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results{\"_with_2shot_prompting\" if use_2shot_prompting else \"\"}_thres={match_threshold}_{knockout_map_type}_maps.pt')\n",
    "        heuristics_knockout_results = [h for h in heuristics_knockout_results if \\\n",
    "                                        len(h.ablated_neurons)>= MIN_NEURONS_PER_HEURISTIC and \n",
    "                                        h.ablated_neuron_matching_score >= MIN_SCORE_SUM_PER_HEURISTIC]\n",
    "        if knockout_map_type == \"KV\":\n",
    "            # No point in looking at operand heuristics\n",
    "            heuristics_knockout_results = [h for h in heuristics_knockout_results if h.heuristic_name.startswith('result')]\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e}\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    baseline_related = torch.tensor([h.baseline_related for h in heuristics_knockout_results])\n",
    "    ablated_related = torch.tensor([h.ablated_related for h in heuristics_knockout_results])\n",
    "    return baseline_related.mean().item(), ablated_related.mean().item()\n",
    "\n",
    "match_threshold = 0.6\n",
    "MIN_NEURONS_PER_HEURISTIC = 20.0\n",
    "MIN_SCORE_SUM_PER_HEURISTIC = 20.0\n",
    "knockout_map_type = \"HYBRID\"\n",
    "use_2shot_prompting = False\n",
    "operators_to_process = range(len(OPERATORS))\n",
    "\n",
    "accs_per_step = []\n",
    "ablated_accs_per_step = []\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "for operator_idx in operators_to_process:\n",
    "    accs_per_step.append([get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting)[0] for step in steps])\n",
    "    ablated_accs_per_step.append([get_mean_baseline_and_ablated_accs(step, operator_idx, use_2shot_prompting)[1] for step in steps])\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "fig = go.Figure()\n",
    "for i, op in enumerate(OPERATORS):\n",
    "    fig.add_trace(go.Scatter(x=steps, y=accs_per_step[i], mode='lines', name=f'{op}', line=dict(color=colors[i], dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=steps, y=ablated_accs_per_step[i], mode='lines', name=f'{op} (Ablated)', line=dict(color=colors[i])))\n",
    "# fig.add_trace(go.Scatter(x=steps, y=torch.tensor(accs_per_step).mean(dim=0).tolist(), mode='lines', name=f'Mean', line=dict(color=colors[i+1], dash='dash')))\n",
    "# fig.add_trace(go.Scatter(x=steps, y=torch.tensor(ablated_accs_per_step).mean(dim=0).tolist(), mode='lines', name=f'Mean (Ablated)', line=dict(color=colors[i+1])))\n",
    "fig.update_layout(\n",
    "    title='Heuristic-based accuracies over training steps',\n",
    "    xaxis_title='Training step',\n",
    "    yaxis_title='Accuracy',\n",
    "    legend_title='',\n",
    "    width=500,\n",
    "    height=400,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/heuristics_knockout_across_training.pdf')\n",
    "pio.write_image(fig, f'./figs/heuristics_knockout_across_training.svg')\n",
    "\n",
    "avg_corr = 0\n",
    "for op_idx in range(len(OPERATORS)):\n",
    "    knockout_diff_per_step = [accs_per_step[op_idx][i] - ablated_accs_per_step[op_idx][i] for i in range(len(steps))]\n",
    "    corr = pearsonr(accs_per_step[op_idx], knockout_diff_per_step)[0]\n",
    "    print(f\"{op_idx=}, Correlation of acc to knockout diff: {corr}\")\n",
    "    avg_corr += corr\n",
    "avg_corr /= len(OPERATORS)\n",
    "print(f\"{avg_corr=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the heuristics intersection with a chosen training step \n",
    "# (without categorization, without considering heuristics, just full set intersection of (h, l, n) sets)\n",
    "\n",
    "def get_heuristics_that_appear_across_all_steps(operator_idx, steps):\n",
    "    a = set(load_heuristic_classes(f\"./data/pythia-6.9b-step143000\", operator_idx, knockout_type).keys())\n",
    "    for step in steps:\n",
    "        b = set(load_heuristic_classes(f\"./data/pythia-6.9b-step{step}\", operator_idx, knockout_type).keys())\n",
    "        a = a.intersection(b)\n",
    "    return a\n",
    "\n",
    "THRESHOLD = 0.6\n",
    "knockout_type = \"HYBRID\"\n",
    "use_2shot_prompting = False\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(list(set(steps) - {3000, 13000, 138000, 142000}))\n",
    "print(steps)\n",
    "\n",
    "new_mean_heuristic_intersections = torch.zeros((len(OPERATORS), len(steps)))\n",
    "step_idx_to_compare_to = steps.index(143000)\n",
    "gt_model_name = f\"{PYTHIA_PREFIX}-step{steps[step_idx_to_compare_to]}\"\n",
    "\n",
    "print(f\"Comparing to step {steps[step_idx_to_compare_to]}\")\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    gt_heuristic_classes = load_heuristic_classes(f\"./data/{gt_model_name}\", operator_idx, knockout_type, override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict')\n",
    "    \n",
    "    # Filter by threshold\n",
    "    gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}\n",
    "\n",
    "    # Filter only top-k neurons\n",
    "    neuron_scores = _get_neuron_importance_scores(gt_model_name, operator_idx, use_2shot_prompting)\n",
    "    top_neuron_of_model = {layer: neuron_scores[layer].topk(50).indices.tolist() for layer in neuron_scores.keys()}\n",
    "    gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if n in top_neuron_of_model[l]] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}\n",
    "\n",
    "    # Filter only heuristics that appear in all training steps\n",
    "    gt_heuristic_names = get_heuristics_that_appear_across_all_steps(operator_idx, steps)\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if name in gt_heuristic_names}\n",
    "\n",
    "    # Create a list of (layer, neuron, heuristic_name) tuples\n",
    "    gt_heuristic_neuron_pairs = [(h_name, l, n) for h_name, lns in gt_heuristic_classes.items() for (l, n, s) in lns]\n",
    "    heuristic_intersections = torch.zeros(len(steps))\n",
    "    for step_idx, step in enumerate(steps):\n",
    "        model_name = f\"{PYTHIA_PREFIX}-step{steps[step_idx]}\"\n",
    "        print(\"comparing to\", model_name)\n",
    "        heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", \n",
    "                                                    operator_idx, knockout_type, \n",
    "                                                    override_fileprefix=f'{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict')\n",
    "        heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    "\n",
    "        heuristic_neuron_pairs = [(h_name, l, n) for h_name, lns in heuristic_classes.items() for (l, n, s) in lns]\n",
    "        heuristic_intersections[step_idx] = len(set(gt_heuristic_neuron_pairs).intersection(set(heuristic_neuron_pairs))) / len(gt_heuristic_neuron_pairs)\n",
    "        print(f\"{step=}, {heuristic_intersections[step_idx]}\")\n",
    "    new_mean_heuristic_intersections[operator_idx, :] = heuristic_intersections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the heuristic intersection graph itself\n",
    "\n",
    "# legend = ['+', '-', 'ร', 'รท']\n",
    "legend = [\"Average\"]\n",
    "steps = sorted(set(steps) - {3000, 13000, 138000, 142000})\n",
    "fig = px.line(y=new_mean_heuristic_intersections.mean(dim=0), x=steps, width=300, height=200)\n",
    "fig.update_layout(\n",
    "    yaxis=dict(range=[0.0, 1.0], title=dict(text=\"Intersection ratio\", font=dict(size=16)), tickfont=dict(size=15), tickvals=torch.linspace(0.2, 1, 5), ),\n",
    "    xaxis=dict(title=dict(standoff=5, text=\"Training step\", font=dict(size=16)), tickfont=dict(size=15), tickvals=steps[::4]),\n",
    "    title=dict(\n",
    "        text=\"Heuristic neurons intersection<br>with final checkpoint\",\n",
    "        x=0.55,  # Center the title horizontally\n",
    "        y=0.93,  # Move the title up or down\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(\n",
    "            family=\"Arial\",  # Change font family\n",
    "            size=17,  # Change font size\n",
    "    )),\n",
    "    legend=dict(orientation=\"h\", itemsizing='constant', yanchor=\"bottom\", y=-0.35, xanchor=\"center\", x=0.5, font=dict(size=18)),\n",
    "    margin=dict(t=40, l=0, r=0, b=0),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/heuristics_intersection_across_training.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the faithfulness graph; Once when using all heuristic neurons and once when using mutual neurons to last checkpoint\n",
    "\n",
    "operator_idx = 0\n",
    "faithfulnneses = sorted({int(k[0].split('step')[1]): v for k, v in torch.load(r'./data/pythia-6.9b-step143000/mutual_faithfulness_results_old.pt').items() if k[1] == operator_idx}.items())\n",
    "\n",
    "colors = COLORBLIND_COLORS\n",
    "baseline = [f[1][1].item() for f in faithfulnneses]\n",
    "mutual = [f[1][2].item() for f in faithfulnneses]\n",
    "print((torch.tensor(mutual) / torch.tensor(baseline)))\n",
    "steps = [step for step, _ in faithfulnneses]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=steps, y=baseline, mode='lines', name='All heuristic neurons', line=dict(color=colors[0], dash=\"dot\")))\n",
    "fig.add_trace(go.Scatter(x=steps, y=mutual, mode='lines', name='Overlapping with last checkpoint', line=dict(color=colors[0])))\n",
    "fig.update_layout(\n",
    "    yaxis=dict(range=[0.0, 1.0], title=dict(text=\"Faithfulness\", font=dict(size=16)), tickfont=dict(size=15), tickvals=torch.linspace(0.2, 1, 5)),\n",
    "    xaxis=dict(title=dict(standoff=5, text=\"Training step\", font=dict(size=16)), tickfont=dict(size=15), tickvals=[23000, 63000, 103000, 143000]),\n",
    "    title=dict(\n",
    "        text=\"Faithfulness of circuit with <br>specific heuristic neurons\",\t\n",
    "        x=0.55,  # Center the title horizontally\n",
    "        y=0.93,  # Move the title up or down\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(\n",
    "            family=\"Arial\",  # Change font family\n",
    "            size=17,  # Change font size\n",
    "    )),\n",
    "    width=300,\n",
    "    height=200,\n",
    "    legend=dict(orientation=\"h\", itemsizing='constant', yanchor=\"bottom\", y=0.2, xanchor=\"center\", x=0.5, font=dict(size=15)),\n",
    "    margin=dict(t=40, l=0, r=0, b=0),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/faithfulness_mutual_heuristics_across_training.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the prompt knockout score as a function of training steps\n",
    "\n",
    "steps = find_all_pythia_steps()\n",
    "steps = sorted(list(set(steps) - {3000, 13000, 138000, 142000}))\n",
    "colors = COLORBLIND_COLORS[1:2] + COLORBLIND_COLORS[::-1]\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Heuristic Ablation', line=dict(color='grey')))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Random Ablation', line=dict(dash='dash', color='grey')))\n",
    "\n",
    "for i, chosen_neuron_hard_limit in enumerate([5, 10, 25]):\n",
    "    ablated_results_per_step = torch.zeros((len(OPERATORS), len(steps)))\n",
    "    control_results_per_step = torch.zeros((len(OPERATORS), len(steps)))\n",
    "\n",
    "    # Collect the data to present from the files\n",
    "    for operator_idx in range(len(OPERATORS)):\n",
    "        for step_idx, step in enumerate(steps):\n",
    "            model_name = f\"{PYTHIA_PREFIX}-step{step}\"\n",
    "            neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_prompt_ablation_results_thres=0.6_HYBRID_maps.pt')\n",
    "            assert torch.all(baseline_results == 1)\n",
    "\n",
    "            chosen_neuron_hard_limit_idx = list(neuron_hard_limits).index(chosen_neuron_hard_limit)\n",
    "            ablated_results_per_step[operator_idx, step_idx] = ablated_results[chosen_neuron_hard_limit_idx]\n",
    "            control_results_per_step[operator_idx, step_idx] = control_results[chosen_neuron_hard_limit_idx]\n",
    "\n",
    "    # Targeted Ablation\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=steps, y=ablated_results_per_step[:2].mean(dim=0),\n",
    "        mode='lines',\n",
    "        name=f'{chosen_neuron_hard_limit} neurons',\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "    \n",
    "    # Control Ablation\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=steps, y=control_results_per_step[:2].mean(dim=0),\n",
    "        mode='lines',\n",
    "        name=f'',\n",
    "        showlegend=False,\n",
    "        line=dict(color=colors[i], dash='dot')\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=300,\n",
    "    height=200,\n",
    "    yaxis=dict(range=[0.0, 1.0], title=dict(text=\"Accuracy\", font=dict(size=16)), tickfont=dict(size=15), tickvals=torch.linspace(0.2, 1, 5)),\n",
    "    xaxis=dict(title=dict(standoff=5, text=\"Training step\", font=dict(size=16)), tickfont=dict(size=15), tickvals=steps[:-1:4]),\n",
    "    title=dict(text=\"Effect of heuristic neurons<br>knockout\", x=0.52, y=0.93, xanchor='center', yanchor='top', font=dict(size=17, family=\"Arial\")),\n",
    "    showlegend=False,\n",
    "    # legend=dict(orientation=\"h\", yanchor=\"top\", y=-0.4, xanchor=\"center\", x=0.2, font=dict(size=14), title_text='', traceorder=\"normal\",\n",
    "    #     valign=\"top\",  # Align legend at the top within the margin\n",
    "    #     itemwidth=30,  # Adjust the width of each item\n",
    "    #     tracegroupgap=0,  # Controls the spacing between columns\n",
    "    # ),\n",
    "    margin=dict(t=40, l=0, r=0, b=0),  # Adjust bottom margin for space\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/prompt_knockout_across_training.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shots Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 2-shot-prompted model with 0-shot model\n",
    "\n",
    "model_name = \"pythia-6.9b-step143000\"\n",
    "print(\"Model accuracy: \", torch.load(os.path.join('data', model_name, 'accuracy.pt')))\n",
    "print(\"Model 2-shot accuracy: \", torch.load(os.path.join('data', model_name, 'accuracywith_2shot_prompting.pt')))\n",
    "\n",
    "def top_k_neurons(model_name, op_idx, use_2shot_prompting, k):\n",
    "    def ranking_func(attribution_scores):\n",
    "        return attribution_scores[:, -1].mean(dim=0) + attribution_scores[:, -1].std(dim=0)\n",
    "    neuron_attribution_scores = torch.load(f\"./data/{model_name}/{OPERATOR_NAMES[op_idx]}_node_attribution_scores{'_with_2shot_prompting' if use_2shot_prompting else ''}.pt\")\n",
    "    mlppost_neurons_scores = {layer: ranking_func(neuron_attribution_scores[f'blocks.{layer}.mlp.hook_post']).topk(k).indices.tolist() for layer in range(0, 32)}\n",
    "    return mlppost_neurons_scores\n",
    "\n",
    "for op_idx in [0, 1]:\n",
    "    k = 25\n",
    "    clean_top_neurons = top_k_neurons(model_name, op_idx, False, k)\n",
    "    two_shot_neurons = top_k_neurons(model_name, op_idx, True, k)\n",
    "    for layer in range(14, 32):\n",
    "        assert len(clean_top_neurons[layer]) == len(two_shot_neurons[layer])\n",
    "        mutual_percentage = len(set(clean_top_neurons[layer]).intersection(set(two_shot_neurons[layer]))) / len(clean_top_neurons[layer])\n",
    "        print(f\"Operator {op_idx}, Layer {layer}: {mutual_percentage} of neurons are mutual in 0-shot and 2-shot settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pythia-6.9b-step143000\"\n",
    "name, step = model_name.split('-step')\n",
    "model_path = f\"/mnt/nlp/models/{name}/step{step}\"\n",
    "inner_model = GPTNeoXForCausalLM.from_pretrained(f\"EleutherAI/{name}\", revision=f\"step{step}\", cache_dir=model_path)\n",
    "model = lens.HookedTransformer.from_pretrained(model_name=name, hf_model=inner_model, fold_ln=True, center_unembed=True, center_writing_weights=True, device=device)\n",
    "\n",
    "BEST_SHOTS_PER_OP = {#_PYTHIA6 = {\n",
    "    '+': '17+84=101, 2+4=6, ', #40clean, 85%\n",
    "    '-': '34-20=14; 38-19=19; ', #3 clean, \n",
    "    '*': '23*14=322; 5*6=30; ',\n",
    "    '/': '115/22=5, 98/7=14, '\n",
    "}\n",
    "\n",
    "BEST_SHOTS_PER_OP_PYTHIA12 = {\n",
    "    '+': '17+84=101, 2+4=6, ', #45clean, 87% 2shot\n",
    "    '-': '21-10=11, 105-23=82, ', #43clean, 80% 2shot\n",
    "    '*': '23*14=322; 5*6=30; ', #16clean, 92% 2shot\n",
    "    '/': '58/4=14, 85/4=21, ' #12clean, 73% 2shot\n",
    "}\n",
    "\n",
    "\n",
    "# Baseline shots\n",
    "SHOTS_PER_OP = {\n",
    "    '+': '15+23=38, 17+115=132, ',\n",
    "    '-': '105-23=82, 21-10=11, ',\n",
    "    '*': '5*6=30, 23*14=322, ',\n",
    "    '/': '98/7=14, 115/22=5, '\n",
    "}\n",
    "\n",
    "# Different order\n",
    "SHOTS_PER_OP2 = {\n",
    "    '+': '17+115=132, 15+23=38, ',\n",
    "    '-': '21-10=11, 105-23=82, ', \n",
    "    '*': '23*14=322, 5*6=30, ',\n",
    "    '/': '115/22=5, 98/7=14, '\n",
    "}\n",
    "\n",
    "# ; instead of ,\n",
    "SHOTS_PER_OP3 = {\n",
    "    '+': '17+115=132; 15+23=38; ',\n",
    "    '-': '21-10=11; 105-23=82; ', \n",
    "    '*': '23*14=322; 5*6=30; ',\n",
    "    '/': '115/22=5; 98/7=14; '\n",
    "}\n",
    "\n",
    "# HARDER PROMPTS\n",
    "SHOTS_PER_OP4 = {\n",
    "    '+': '117+56=173, 23+299=322, ',\n",
    "    '-': '221-31=190, 173-28=145, ',\n",
    "    '*': '89*3=267, 18*12=216, ', \n",
    "    '/': '298/14=21, 145/113=1, '\n",
    "}\n",
    "\n",
    "# print(\"0Shot Model accuracy: \", torch.load(os.path.join('data', model_name + \"-0shot\", 'accuracy.pt')))\n",
    "for op in OPERATORS:\n",
    "    min_op = 0 if op != '/' else 1\n",
    "    max_op = 300\n",
    "    clean_prompts = generate_all_prompts_for_operator(op, min_op, max_op, (0, 520))\n",
    "    answers = [str(int(eval(prompt[:-1]))) for prompt in clean_prompts]\n",
    "    # print(op, 'CLEAN', model_accuracy(model, clean_prompts, answers))\n",
    "    prompts = [f\"{BEST_SHOTS_PER_OP[op]}{p}\" for p in clean_prompts]\n",
    "    print(op, 'BEST', model_accuracy(model, prompts, answers))\n",
    "\n",
    "    # prompts = [f\"{SHOTS_PER_OP2[op]}{p}\" for p in clean_prompts]\n",
    "    # print(op, '2', model_accuracy(model, prompts, answers))\n",
    "    # prompts = [f\"{SHOTS_PER_OP3[op]}{p}\" for p in clean_prompts]\n",
    "    # print(op, '3', model_accuracy(model, prompts, answers))\n",
    "    # prompts = [f\"{SHOTS_PER_OP4[op]}{p}\" for p in clean_prompts]\n",
    "    # print(op, '4', model_accuracy(model, prompts, answers))\n",
    "    \n",
    "    # def gen_random_shots(op):\n",
    "    #     # Generate random prompt in the same template as the SHOTS_PER_OP[op]\n",
    "    #     shot1 = random.choice(clean_prompts)\n",
    "    #     ans1 = int(eval(shot1[:-1]))\n",
    "    #     shot2 = random.choice(clean_prompts)\n",
    "    #     ans2 = int(eval(shot2[:-1]))\n",
    "    #     if op == '/'or op == '+':\n",
    "    #         shots = f\"{shot1}{ans1}, {shot2}{ans2}, \"\n",
    "    #     else:\n",
    "    #         shots = f\"{shot1}{ans1}; {shot2}{ans2}; \"\n",
    "    #     return shots\n",
    "    \n",
    "    # shots = gen_random_shots(op)\n",
    "    # prompts = [f\"{shots}{p}\" for p in clean_prompts]\n",
    "    # print(op, shots, model_accuracy(model, prompts, answers))\n",
    "    # shots = gen_random_shots(op)\n",
    "    # prompts = [f\"{shots}{p}\" for p in clean_prompts]\n",
    "    # print(op, shots, model_accuracy(model, prompts, answers))\n",
    "    # shots = gen_random_shots(op)\n",
    "    # prompts = [f\"{shots}{p}\" for p in clean_prompts]\n",
    "    # print(op, shots, model_accuracy(model, prompts, answers))\n",
    "    # shots = gen_random_shots(op)\n",
    "    # prompts = [f\"{shots}{p}\" for p in clean_prompts]\n",
    "    # print(op, shots, model_accuracy(model, prompts, answers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
