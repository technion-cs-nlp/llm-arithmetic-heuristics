{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs arithmetic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a playground for the various experiments described in the paper (as well as additional experiments which weren't mentioned in the paper, for reference).\n",
    "\n",
    "Most of the main experiments were further written to separate files (those named ```script_.*```). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from general_utils import set_deterministic, set_cuda_device\n",
    "set_cuda_device(0)\n",
    "\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import transformer_lens as lens\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import widgets\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "from prompt_generation import generate_prompts, separate_prompts_and_answers, generate_all_prompts_for_operator, POSITIONS, OPERATORS, OPERATOR_NAMES, _is_number, _get_operand_range\n",
    "from attention_analysis import ov_transition_analysis, two_operands_arithmetic_qk_heatmap\n",
    "from visualization_utils import imshow, line, scatter, visualize_arithmetic_attention_patterns, multiple_lines, scatter_with_labels\n",
    "from evaluation_utils import model_accuracy_on_simple_prompts\n",
    "from circuit_utils import topk_effective_components\n",
    "from component import Component\n",
    "from general_utils import generate_activations, set_deterministic, get_neuron_importance_scores, get_model_consts, safe_eval, load_model, reduce_dimensionality\n",
    "from linear_probing import linear_probe_across_layers\n",
    "from metrics import indirect_effect\n",
    "from eap.attr_patching import node_attribution_patching\n",
    "from eap.eap_wrapper import EAP\n",
    "from circuit import Circuit\n",
    "from evaluation_utils import model_accuracy, circuit_faithfulness_with_mean_ablation\n",
    "from activation_patching import activation_patching_experiment\n",
    "from model_analysis_consts import LLAMA3_8B_CONSTS\n",
    "from heuristics_classification import HeuristicAnalysisData, classify_heuristic_neurons, load_heuristic_classes\n",
    "from heuristics_analysis import get_relevant_prompts, get_neurons_associated_with_prompt, heuristic_class_knockout_experiment, prompt_knockout_experiment, is_associated_heuristic\n",
    "\n",
    "\n",
    "COLORBLIND_COLORS = ['#0173b2', '#de8f05', '#029e73','#d55e00', '#cc78bc', '#ca9161', '#fbafe4', '#949494', '#ece133', '#56b4e9']\n",
    "torch.set_grad_enabled(False)\n",
    "device = 'cuda'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-8b\"\n",
    "model_path = \"/mnt/nlp/models/models--meta-llama--Meta-Llama-3-8B/snapshots/cd892e8f4da1043d4b01d5ea182a2e8412bf658f\"\n",
    "\n",
    "if model_path is None:\n",
    "    model = lens.HookedTransformer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", fold_ln=True, center_unembed=True, center_writing_weights=True, device=device)\n",
    "else:\n",
    "    model = lens.HookedTransformer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", \n",
    "                                                hf_model=AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True),\n",
    "                                                fold_ln=True, center_unembed=True, center_writing_weights=True, device=device)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correct prompts for the circuit discovery.\n",
    "# Corrupt prompts are chosen later per experiment, and differ in operator and/or operands.\n",
    "\n",
    "max_op = 300\n",
    "op_ranges = {'+': (0, max_op), '-': (0, max_op), '*': (0, max_op), '/': (1, max_op)}\n",
    "analysis_prompts_file_path = fr'./data/{model_name}/large_prompts_and_answers_max_op={max_op}.pkl'\n",
    "\n",
    "set_deterministic(42)\n",
    "\n",
    "if os.path.exists(analysis_prompts_file_path):\n",
    "    with open(analysis_prompts_file_path, 'rb') as f:\n",
    "        large_prompts_and_answers = pickle.load(f)\n",
    "else:\n",
    "    large_prompts_and_answers = generate_prompts(model, operand_ranges=op_ranges, correct_prompts=True, num_prompts_per_operator=None, single_token_number_range=(0, LLAMA3_8B_CONSTS.max_single_token))\n",
    "    with open(analysis_prompts_file_path, 'wb') as f:\n",
    "        pickle.dump(large_prompts_and_answers, f)\n",
    "\n",
    "for i in range(len(large_prompts_and_answers)):\n",
    "    random.shuffle(large_prompts_and_answers[i])\n",
    "\n",
    "\n",
    "correct_prompts_and_answers = [pa[:50] for pa in large_prompts_and_answers]\n",
    "evaluation_prompts_and_answers = [pa[50:] for pa in large_prompts_and_answers]\n",
    "\n",
    "try:\n",
    "    with open(fr'./data/{model_name}/large_incorrect_prompts_and_answers_max_op={max_op}.pkl', 'rb') as f:\n",
    "        incorrect_prompts_and_answers = pickle.load(f)\n",
    "except:\n",
    "    incorrect_prompts_and_answers = generate_prompts(model, op_ranges, validate_numerals=True, correct_prompts=False, num_prompts_per_operator=None, single_token_number_range=(0, LLAMA3_8B_CONSTS.max_single_token))\n",
    "    with open(fr'./data/{model_name}/large_incorrect_prompts_and_answers_max_op={max_op}.pkl', 'wb') as f:\n",
    "        pickle.dump(incorrect_prompts_and_answers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for operator in OPERATORS:\n",
    "    min_op = 1 if operator == '/' else 0\n",
    "    acc = model_accuracy_on_simple_prompts(model, min_op, max_op, (0, get_model_consts(model_name).max_single_token), [operator])\n",
    "    print(f\"The model accuracy on simple prompts with operator {operator} is: {acc :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circuit Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual discovery code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial, manual activation patching for separate attention heads + MLPs\n",
    "# Fuller analysis is done in script_circuit_localization.py\n",
    "\n",
    "operator_idx = 0\n",
    "correct_pa = correct_prompts_and_answers[operator_idx]\n",
    "corrupt_pa = random.sample(sum(correct_prompts_and_answers, []), len(correct_pa))\n",
    "for token_pos in [4, 3, 2, 1]:\n",
    "    seed = 42\n",
    "    ie_over_layers_and_heads_and_mlp = torch.zeros((model.cfg.n_layers, model.cfg.n_heads + 1), dtype=torch.float32)\n",
    "\n",
    "    def head_hooking_func(value, hook, head_index, token_pos, cache):\n",
    "        if token_pos is None:\n",
    "            value[:, :, head_index, :] = cache[hook.name][:, :, head_index, :] # For z hooking\n",
    "        else:\n",
    "            value[:, token_pos, head_index, :] = cache[hook.name][:, token_pos, head_index, :] # For z hooking\n",
    "        return value\n",
    "\n",
    "    # MLP\n",
    "    ie_over_layers_and_heads_and_mlp[:, -1] = activation_patching_experiment(model, correct_pa, corrupt_prompts_and_answers=corrupt_pa, hookpoint_name='mlp_post',\n",
    "                                                                            metric='IE-Logits',\n",
    "                                                                            token_pos=token_pos,\n",
    "                                                                            random_seed=seed).mean(dim=0)\n",
    "\n",
    "    # Attention heads   \n",
    "    for head_idx in range(model.cfg.n_heads):\n",
    "        head_hook_fn = partial(head_hooking_func, head_index=head_idx, token_pos=token_pos)\n",
    "        ie_over_layers_and_heads_and_mlp[:, head_idx] = activation_patching_experiment(model, correct_pa, corrupt_prompts_and_answers=corrupt_pa, hookpoint_name='z',\n",
    "                                                                                        metric='IE-Logits',\n",
    "                                                                                        token_pos=token_pos,\n",
    "                                                                                    hook_func_overload=head_hook_fn, random_seed=seed).mean(dim=0)\n",
    "\n",
    "    imshow(ie_over_layers_and_heads_and_mlp[:, :], x=[str(i) for i in range(model.cfg.n_heads)] +['mlp'], width=400, labels={'x':'Attn Head Idx / MLP', 'y': 'Layer'}, title='IE of different attention heads and MLP<br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe for answer in last token position\n",
    "\n",
    "# Initial linear probing code. Meant to probe for answer token in the residual stream across layers and positions.\n",
    "# Fuller code can be found in script_linear_probe.py\n",
    "\n",
    "max_op = 300\n",
    "max_answer_value = 1000\n",
    "\n",
    "probe_accs = {}\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    activations = None\n",
    "    for pos_to_probe in POSITIONS:\n",
    "        print(f\"{pos_to_probe=}, {operator_idx=}\")\n",
    "\n",
    "        # Get training and testing data for the linear probe\n",
    "        correct_prompts = separate_prompts_and_answers(large_prompts_and_answers[operator_idx])[0]\n",
    "        random.shuffle(correct_prompts)\n",
    "        answers = torch.tensor([safe_eval(prompt[:-1]) for prompt in correct_prompts])\n",
    "\n",
    "        # Generate the activations once for all positions and cache it\n",
    "        if activations is None:\n",
    "            components = [Component('resid_post', layer=i) for i in range(model.cfg.n_layers)]\n",
    "            activations = generate_activations(model, correct_prompts, components, pos=None)\n",
    "\n",
    "        pos_activations = {i: activations[i][:, pos_to_probe] for i in range(model.cfg.n_layers)}\n",
    "        probe_accs[(operator_idx, pos_to_probe)] = linear_probe_across_layers(model, pos_activations, answers, max_answer_value)[1]\n",
    "        line(probe_accs[(operator_idx, pos_to_probe)], range_y=(0.0, 1.0), labels={'x': 'Layer', 'y': 'Test Accuracy'}, title=f'{OPERATOR_NAMES[operator_idx]} probing Accuracy Per Layer (At Position {pos_to_probe})')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circuit Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mean activation cache for all relevant components\n",
    "\n",
    "max_op = 300\n",
    "eval_mean_cache_path = f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt'\n",
    "if os.path.exists(eval_mean_cache_path):\n",
    "    cached_activations = torch.load(eval_mean_cache_path)\n",
    "    print('Loaded cached activations from file')\n",
    "else:\n",
    "    all_heads = [(l, h) for h in range(model.cfg.n_heads) for l in range(model.cfg.n_layers)]\n",
    "    all_mlps = list(range(model.cfg.n_layers))\n",
    "    model.set_use_attn_result(True)\n",
    "    all_components = [Component('z', layer=l, head=h) for (l, h) in all_heads] + \\\n",
    "                     [Component('result', layer=l, head=h) for (l, h) in all_heads] + \\\n",
    "                     [Component('mlp_post', layer=l) for l in all_mlps] + \\\n",
    "                     [Component('mlp_in', layer=l) for l in all_mlps]\n",
    "    all_prompts = [f\"{x}{operator}{y}=\" for operator in OPERATORS for x in range(0, max_op) for y in range(0, max_op)]\n",
    "    cached_activations = generate_activations(model, all_prompts, all_components, pos=None, reduce_mean=True)\n",
    "    cached_activations = {c: a[None, ...].to(device='cpu').repeat(50, 1, 1) for c, a in zip(all_components, cached_activations)}\n",
    "    torch.save(cached_activations, eval_mean_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial code for manual evaluation of the discovered arithmetic circuit.\n",
    "# Each circuit includes all MLPs and a subset of attention heads.\n",
    "\n",
    "\n",
    "def build_circuit(operator_idx):      \n",
    "    if operator_idx == 0:\n",
    "        # Addition\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 3), (5, 31), (14, 12), (15, 13), (16, 21)]]\n",
    "    elif operator_idx == 1:\n",
    "        # Subtraction\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (13, 21), (13, 22), (14, 12), (15, 13), (16, 21)]]\n",
    "    elif operator_idx == 2:\n",
    "        # Multiplication\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 30), (8, 15), (9, 26), (13, 18), (13, 21), (13, 22), \n",
    "                                                                (14, 12), (14, 13), (15, 8), (15, 13), (15, 14), (15, 15), (16, 3), \n",
    "                                                                (16, 21), (17, 24), (17, 26), (18, 16), (20, 2), (22, 1)]]\n",
    "    elif operator_idx == 3:\n",
    "        # Division\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 31), (15, 13), (15, 14), (16, 21), (18, 16)]]\n",
    "\n",
    "    full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)]\n",
    "    full_circuit = Circuit(model.cfg)\n",
    "    for c in list(set(heads + full_mlps)):\n",
    "        full_circuit.add_component(c)\n",
    "    return full_circuit\n",
    "\n",
    "\n",
    "operator_idx = 0\n",
    "max_op = 300\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "\n",
    "avg_nl_acc = 0\n",
    "avg_acc = 0\n",
    "seeds = [42, 412, 32879, 123, 436]\n",
    "for seed in seeds:\n",
    "    set_deterministic(seed)\n",
    "    prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "    print(prompts_and_answers)\n",
    "\n",
    "    full_circuit = build_circuit(operator_idx)\n",
    "    nl_acc = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "    avg_nl_acc += nl_acc\n",
    "    print(f\"Normalized Logit Acc (Seed {seed}): {nl_acc:.3f}\")\n",
    "\n",
    "avg_nl_acc = avg_nl_acc / len(seeds)\n",
    "print(f\"Avg Normalized Logit Acc: {avg_nl_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the (pre-calculated) indirect effects of each component to \n",
    "# evaluate the circuit based on the amount of attention heads (by including only the highest effect attention heads)\n",
    "\n",
    "def process_ie_maps(ie_maps):\n",
    "    # Average across seeds\n",
    "    summed_seed_ie_maps = {}\n",
    "    seeds = set()\n",
    "    for op_idx, pos, seed in ie_maps.keys():\n",
    "        seeds.add(seed)\n",
    "        if (op_idx, pos) not in summed_seed_ie_maps:\n",
    "            summed_seed_ie_maps[(op_idx, pos)] = ie_maps[(op_idx, pos, seed)]\n",
    "        else:\n",
    "            summed_seed_ie_maps[(op_idx, pos)] += ie_maps[(op_idx, pos, seed)]\n",
    "    ie_maps = {k: v / len(seeds) for (k, v) in summed_seed_ie_maps.items()}\n",
    "\n",
    "    # Mean across positions\n",
    "    ie_maps = {op_idx: torch.stack([ie_maps[(op_idx, pos)] for pos in POSITIONS]).mean(dim=0) for op_idx in range(4)}\n",
    "\n",
    "    # Tensorify and log scale\n",
    "    ie_maps = torch.stack([ie_maps[op_idx] for op_idx in range(len(OPERATORS))]) # ops, Layers, heads+mlp\n",
    "    ie_maps = np.log1p(ie_maps)\n",
    "    return ie_maps\n",
    "\n",
    "ie_maps = process_ie_maps(torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt'))\n",
    "max_n_heads = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the faithfulness of the circuit with only some of the heads to understand if indeed a small number of sparse heads\n",
    "# is enough to achieve high faithfulness to the model\n",
    "\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "\n",
    "def build_circuit(operator_idx, n_heads):\n",
    "    heads = list(topk_effective_components(model, ie_maps[operator_idx], k=100, heads_only=True).keys())[:n_heads]\n",
    "    full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)]\n",
    "    full_circuit = Circuit(model.cfg)\n",
    "    for c in list(set(heads + full_mlps)):\n",
    "        full_circuit.add_component(c)\n",
    "    return full_circuit\n",
    "\n",
    "max_n_heads = 100\n",
    "seeds = [42, 412, 32879, 123, 436]\n",
    "faithfulness_results = torch.zeros((len(seeds), len(OPERATORS), max_n_heads))\n",
    "\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        set_deterministic(seed)\n",
    "        prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "        print(operator_idx, seed)\n",
    "\n",
    "        for n_heads in range(0, max_n_heads):\n",
    "            full_circuit = build_circuit(operator_idx, n_heads)\n",
    "            nl_acc = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "            faithfulness_results[seed_idx, operator_idx, n_heads] = nl_acc\n",
    "            print(f\"{seed=}, operator={OPERATORS[operator_idx]}, {n_heads=}: Faithfulness: {nl_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the average attention patterns of the heads with the highest indirect effect in the circuit\n",
    "\n",
    "# Change to the visualized operator index\n",
    "operator_idx = 0\n",
    "\n",
    "# Get the indirect effect of each component\n",
    "ie_maps = process_ie_maps(torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt'))\n",
    "most_effective_heads = topk_effective_components(model, ie_maps[operator_idx], k=20, heads_only=True) \n",
    "\n",
    "# Calculate the activation of the important heads for all valid arithmetic prompts\n",
    "min_op = 1 if operator_idx == 3 else 0\n",
    "prompts = generate_all_prompts_for_operator(OPERATORS[operator_idx], min_op, max_op, single_token_number_range=(0, LLAMA3_8B_CONSTS.max_single_token))\n",
    "\n",
    "# Visualize the attention patterns of the most effective heads\n",
    "head_html, head_patterns = visualize_arithmetic_attention_patterns(model, most_effective_heads, prompts, use_bos_token=True, return_raw_patterns=True)\n",
    "torch.save((head_html, most_effective_heads, head_patterns), f'./data/{model_name}/mean_attn_head_patterns_{OPERATOR_NAMES[operator_idx]}.pt')\n",
    "display(head_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present the QK circuit of attention heads.\n",
    "\n",
    "max_op = 150\n",
    "\n",
    "# Run once to calculate the QK heatmaps\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    attention_values_file_path = f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_lastpos_attn_grid_max_operand={max_op}.pt'\n",
    "    if os.path.exists(attention_values_file_path):\n",
    "        continue\n",
    "    else:\n",
    "        attention_pattern_values = two_operands_arithmetic_qk_heatmap(model, OPERATORS[operator_idx], maximal_operand_value=max_op, dst_token_position=-1, show_progress=True)\n",
    "        torch.save(attention_pattern_values, attention_values_file_path)\n",
    "\n",
    "\n",
    "operator_idx = 0\n",
    "all_attn_values = [torch.load(f'./data/{model_name}/{OPERATOR_NAMES[i]}_lastpos_attn_grid_max_operand={max_op}.pt') for i in range(len(OPERATORS))]\n",
    "src_tokens = ['BOS', 'Operand1', 'Operator', 'Operand2', '=']\n",
    "\n",
    "# Define the slider widgets\n",
    "operator_slider = widgets.IntSlider(min=0, max=len(OPERATORS) - 1, value=0, description='Operator:')\n",
    "layer_slider = widgets.IntSlider(min=0, max=model.cfg.n_layers - 1, value=0, description='Layer:')\n",
    "head_slider = widgets.IntSlider(min=0, max=model.cfg.n_heads - 1, value=0, description='Head:')\n",
    "src_pos_slider = widgets.IntSlider(min=0, max=len(src_tokens) - 1, value=0, description='Source Position:')\n",
    "\n",
    "# Define the update function\n",
    "def show_attention_pattern(op, layer, head, src_pos):\n",
    "    attention_pattern_values = all_attn_values[op]\n",
    "    attn_visualization = attention_pattern_values[layer, head, :, :, src_pos]\n",
    "    plt.imshow(attn_visualization, cmap='hot', vmin=0.0, vmax=1.0, interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Operand1')\n",
    "    plt.xlabel('Operand2')  \n",
    "    plt.title(f'Attention Pattern (Layer: {layer}, Head: {head}, Source Token: {src_tokens[src_pos]})')\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the intereveractive widget\n",
    "interactive_plot = widgets.interactive(show_attention_pattern, op=operator_slider, layer=layer_slider, head=head_slider, src_pos=src_pos_slider)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present the OV circuit of attention heads. This is useful for linear projection heads.\n",
    "\n",
    "arithmetic_words = [str(i) for i in range(0, 1000)]\n",
    "\n",
    "layer_slider = widgets.IntSlider(min=0, max=model.cfg.n_layers-1, value=16, description='Layer:')\n",
    "head_slider = widgets.IntSlider(min=0, max=model.cfg.n_heads-1, value=21, description='Head:')\n",
    "\n",
    "def show_ov_circuit(layer, head):\n",
    "    ov_circuit_heatmap = ov_transition_analysis(model, layer, head, arithmetic_words)\n",
    "    ov_circuit_heatmap = ov_circuit_heatmap.cpu().numpy()\n",
    "    plt.imshow(ov_circuit_heatmap, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('y')\n",
    "    plt.xlabel('x')\n",
    "    plt.title(f'OV Visualization (Layer: {layer}, Head: {head})')\n",
    "    plt.show()\n",
    "interactive_plot = widgets.interactive(show_ov_circuit, layer=layer_slider, head=head_slider)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-neuron attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run node attribution patching (https://www.neelnanda.io/mechanistic-interpretability/attribution-patching) \n",
    "# to get a per-neuron effect approximation. \n",
    "# This is a faster method than running the activation patching described in the paper, but gives slightly less accurate results.\n",
    "\n",
    "set_deterministic(42)\n",
    "\n",
    "# Run node attribution patching for all operators\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    model_cpu = load_model(model_name, model_path, device='cpu')\n",
    "    model_cpu.set_use_attn_result(True)\n",
    "\n",
    "    prompts_and_answers = correct_prompts_and_answers[operator_idx]\n",
    "    corrupt_prompts_and_answers = random.sample(sum(correct_prompts_and_answers, []), k=len(prompts_and_answers)) # Sample randomly from all prompts\n",
    "\n",
    "    attribution_scores = node_attribution_patching(model_cpu, prompts_and_answers, corrupt_prompts_and_answers,\n",
    "                                                attributed_hook_names=['mlp.hook_post'],\n",
    "                                                metric='IE', batch_size=1)\n",
    "    torch.save(attribution_scores, f\"./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_node_attribution_scores.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early MLP(s) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the activation of the highest-effect neurons in early MLPs (this is mainly (only?) valid for MLP0 as we observe\n",
    "# the effect of the MLP on a single token, which ignores the role of pre-MLP attention heads.\n",
    "\n",
    "operator_idx = 0\n",
    "OP1_POS, OP2_POS = 1, 3\n",
    "k_neurons = 5\n",
    "layer = 0\n",
    "\n",
    "# Find the highest-effect neurons\n",
    "mlppost_neuron_scores = get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=OP1_POS)\n",
    "top_mlp_neurons = mlppost_neuron_scores[layer].topk(k_neurons).indices.tolist()\n",
    "\n",
    "# Calculate the MLP activations on a range of nuemrical tokens\n",
    "operand_values = [str(i) for i in range(500)] + ['+', '-', '*', '/', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero', 'ten'] + ['february', 'march', 'april']\n",
    "activations = generate_activations(model, operand_values, [Component('mlp_post', layer=layer)], pos=-1)[0]\n",
    "\n",
    "# Calculate the logit lens of the relevant V vectors for the top neurons\n",
    "vector_inputs = model.blocks[layer].mlp.W_out[top_mlp_neurons, :]\n",
    "vector_logits = vector_inputs @ model.W_U\n",
    "arithmetic_tokens = model.to_tokens([str(i) for i in range(500)], prepend_bos=False)\n",
    "v_tokens = 10\n",
    "\n",
    "# For each important neuron, show its activation as a function of the input token; And a list of the top boosted (and inhibited) \n",
    "# tokens for the corresponding V vector of that neuron\n",
    "for i, neuron_idx in enumerate(top_mlp_neurons):\n",
    "    neuron_activations = activations[:, neuron_idx]\n",
    "    line(neuron_activations, title=f'Neuron {neuron_idx} activations', x=operand_values, labels={'y': 'Activation'})\n",
    "    \n",
    "    topk_tokens = model.to_str_tokens(vector_logits[i].topk(v_tokens).indices, prepend_bos=False)\n",
    "    topk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens).indices], prepend_bos=False)\n",
    "    bottomk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens, largest=False).indices], prepend_bos=False)\n",
    "    print(f'Neuron {neuron_idx} logit lens:')\n",
    "    print(f'Top overall {v_tokens} tokens: {topk_tokens}')\n",
    "    print(f'Top arithmetic {v_tokens} tokens: {topk_arithmetic_tokens}')\n",
    "    print(f'Bottom arithmetic {v_tokens} tokens: {bottomk_arithmetic_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different dimensionallity reduction techniques on the output of early MLPs\n",
    "# to see if we can find any interesting patterns.\n",
    "\n",
    "max_op = 300\n",
    "visualize_mlp = 17\n",
    "mlps_to_test = [Component('mlp_out', layer=i) for i in list(range(0, 17))]\n",
    "dim_reduce_type = 'umap'\n",
    "\n",
    "# Generate activations (this can be cached after first run for faster observations)\n",
    "prompts = [f'{x}+{y}=' for x in range(max_op) for y in range(max_op)]\n",
    "activations = generate_activations(model, prompts, mlps_to_test, pos=-1)\n",
    "\n",
    "# Reduce dimensionality and visualize\n",
    "component = mlps_to_test[visualize_mlp]\n",
    "x, y = reduce_dimensionality(activations[visualize_mlp].cpu(), type=dim_reduce_type)\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y, mode='markers',\n",
    "                                marker={'color': [eval(p[:-1]) % 2 for p in prompts]}, \n",
    "                                hovertext=[f'{p}{eval(p[:-1])}' for p in prompts])) \n",
    "fig.update_layout(title=f'{dim_reduce_type} of arithmetic token embeddings post MLP{component.layer}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP KV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MLPPost neuron scores in the last token position\n",
    "# and analyze K and V vectors (https://arxiv.org/abs/2012.14913) for top neurons\n",
    "\n",
    "operator_idx = 0\n",
    "pos = -1\n",
    "k_neurons = 10\n",
    "layer = 26\n",
    "max_op_visualization = 50 # Can increase this value for higher resolutions activation patterns, at the cost of runtime\n",
    "\n",
    "# Visualize highest-effect neurons in the MLP\n",
    "mlppost_neuron_scores = get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=pos)\n",
    "line(mlppost_neuron_scores[layer])\n",
    "important_neurons = mlppost_neuron_scores[layer].topk(k_neurons, largest=True).indices.tolist()\n",
    "\n",
    "# Calculate the logit lens of the relevant V vectors for the top neurons\n",
    "important_vectors = model.blocks[layer].mlp.W_out[important_neurons, :]\n",
    "vector_logits = important_vectors @ model.W_U\n",
    "\n",
    "# Observe the logits of the token prior to the interesting MLP\n",
    "w_in_logits = (model.blocks[layer].mlp.W_in[:, important_neurons].T @ model.W_U) #+ model.b_U\n",
    "\n",
    "# We only care about the logits of the arithmetic tokens\n",
    "arithmetic_labels = [label for label in model.tokenizer.vocab if _is_number(label.strip(\" \"))]\n",
    "arithmetic_tokens = model.to_tokens(arithmetic_labels, prepend_bos=False).view(-1)\n",
    "\n",
    "# Generate the key activation pattern for the neurons in the MLP\n",
    "prompts = [f'{x}{OPERATORS[operator_idx]}{y}=' for x in range(max_op_visualization) for y in range(max_op_visualization)]\n",
    "all_prompts_activations = generate_activations(model, prompts, [Component('mlp_post', layer=layer)], pos=pos)[0]\n",
    "\n",
    "# Present all of the information for the top neurons ()\n",
    "v_tokens = 10\n",
    "for i, neuron in enumerate(important_neurons):\n",
    "    topk_tokens = model.to_str_tokens(vector_logits[i].topk(v_tokens).indices, prepend_bos=False)\n",
    "    topk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens).indices], prepend_bos=False)\n",
    "    bottomk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens, largest=False).indices], prepend_bos=False)\n",
    "\n",
    "    topk_w_in_tokens = model.to_str_tokens(w_in_logits[i].topk(v_tokens).indices, prepend_bos=False)\n",
    "    topk_w_in_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[w_in_logits[i, arithmetic_tokens].view(-1).topk(v_tokens).indices], prepend_bos=False)\n",
    "    bottomk_w_in_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[w_in_logits[i, arithmetic_tokens].view(-1).topk(v_tokens, largest=False).indices], prepend_bos=False)\n",
    "\n",
    "    print(f'Neuron {neuron} logit lens:')\n",
    "    print(f'IE effect: {mlppost_neuron_scores[layer][neuron]}')\n",
    "    \n",
    "    activation_img = all_prompts_activations[:, neuron].reshape((max_op_visualization, max_op_visualization))\n",
    "    imshow(activation_img, x=list(range(max_op_visualization)), y=list(range(max_op_visualization)), labels={'x': 'Operand2', 'y': 'Operand1'}, width=600,\n",
    "        title=f'Neuron {neuron} activations in MLP {layer} (pos {pos}) as function of operands')\n",
    "\n",
    "    print(f'Top overall {v_tokens} tokens: {topk_tokens}')\n",
    "    print(f'Top overall W_in {v_tokens} tokens: {topk_w_in_tokens}')\n",
    "\n",
    "    print(f'Top arithmetic {v_tokens} tokens: {topk_arithmetic_tokens}')\n",
    "    print(list(zip(topk_arithmetic_tokens, vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens, largest=True).values.tolist())))\n",
    "    print(f'Top arithmetic W_in{v_tokens} tokens: {topk_w_in_arithmetic_tokens}')\n",
    "\n",
    "\n",
    "    print(f'Bottom arithmetic {v_tokens} tokens: {bottomk_arithmetic_tokens}')\n",
    "    print(list(zip(bottomk_arithmetic_tokens, vector_logits[i, arithmetic_tokens].view(-1).topk(v_tokens, largest=False).values.tolist())))\n",
    "    print(f'Bottom arithmetic W_in {v_tokens} tokens: {bottomk_w_in_arithmetic_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-Neuron evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the circuit with a sparse subset of neurons in each middle- and late-layer MLP.\n",
    "# This is an initial investigation, a full analysis is done in script_topk_neuron_eval.py.\n",
    "\n",
    "set_deterministic(42)\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "operator_idx = 0\n",
    "prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "\n",
    "# Ranking neurons according to Attribution patching\n",
    "mlppost_neuron_scores = get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=-1)\n",
    "\n",
    "def build_circuit(operator_idx, mlp_top_neurons):      \n",
    "    if operator_idx == 0:\n",
    "        # Addition\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 3), (5, 31), (14, 12), (15, 13), (16, 21)]]\n",
    "    elif operator_idx == 1:\n",
    "        # Subtraction\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (13, 21), (13, 22), (14, 12), (15, 13), (16, 21)]]\n",
    "    elif operator_idx == 2:\n",
    "        # Multiplication\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 30), (8, 15), (9, 26), (13, 18), (13, 21), (13, 22), \n",
    "                                                                (14, 12), (14, 13), (15, 8), (15, 13), (15, 14), (15, 15), (16, 3), \n",
    "                                                                (16, 21), (17, 24), (17, 26), (18, 16), (20, 2), (22, 1)]]\n",
    "    elif operator_idx == 3:\n",
    "        # Division\n",
    "        heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 31), (15, 13), (15, 14), (16, 21), (18, 16)]]\n",
    "\n",
    "    partial_mlp_layers = list(range(get_model_consts(model_name).first_heuristics_layer, model.cfg.n_layers))\n",
    "    full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers) if l not in partial_mlp_layers]\n",
    "    partial_mlps = [Component('mlp_post', layer=l, neurons=mlp_top_neurons[l]) for l in partial_mlp_layers]    \n",
    "    full_circuit = Circuit(model.cfg)\n",
    "    for c in list(set(heads + full_mlps + partial_mlps)):\n",
    "        full_circuit.add_component(c)\n",
    "    return full_circuit\n",
    "\n",
    "\n",
    "k_values = sorted([0, 10, 25, 50, 75, 100, 150] + list(range(200, 1000, 100)) + list(range(1000, 14000, 200)) + list(range(14000, model.cfg.d_mlp, 20)) + [model.cfg.d_mlp])\n",
    "faithfulness_per_k = torch.zeros((len(k_values),))\n",
    "for i, k in enumerate(k_values):\n",
    "    mlp_top_neurons = {}\n",
    "    attn_top_neurons = {}\n",
    "    for layer in range(1, model.cfg.n_layers):\n",
    "        mlp_top_neurons[layer] = mlppost_neuron_scores[layer].topk(k).indices.tolist()\n",
    "    full_circuit = build_circuit(operator_idx, mlp_top_neurons)\n",
    "    faithfulness_per_k[i] = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "    print(f\"Top-k neurons per layer: {k};\\tFaithfulness: {faithfulness_per_k[i].item()}\")\n",
    "\n",
    "line(faithfulness_per_k, x=k_values, range_y=(0, 1.0), title=f'(Normalized Logit) faithfulness as a function of top k Neurons in each middle and late MLP', labels={'x':'k', 'y':'Faithfulness'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions to be used later.\n",
    "# Some global values used in these functions are defined in later cells and need to be run before CALLING these functions. Ugly, but that's what you get at a deadline.\n",
    "\n",
    "def present_neuron(layer, neuron, use_kv_maps=True):\n",
    "    \"\"\"\n",
    "    Visualizes and analyzes the activations and numerical token logits of a specific neuron.\n",
    "\n",
    "    Args:\n",
    "        layer (int): The layer number in the model where the neuron is located.\n",
    "        neuron (int): The neuron index within the specified layer.\n",
    "        use_kv_maps (bool, optional): Flag to determine whether to use key-value maps for prompts activations. \n",
    "                                      Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Choose the relevant activation pattern (either multiplied by V vector logits (for direct heuristics) or not multiplied (for indirect heuristics)\n",
    "    if use_kv_maps:\n",
    "        prompts_activations = kv_prompts_activations\n",
    "    else:\n",
    "        prompts_activations = k_prompts_activations\n",
    "    v_tokens = 10\n",
    "\n",
    "    # Get the logits of numerical tokens in the V vector\n",
    "    vector_logits = model.blocks[layer].mlp.W_out[neuron] @ model.W_U\n",
    "    topk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[arithmetic_tokens].view(-1).topk(v_tokens).indices], prepend_bos=False)\n",
    "    bottomk_arithmetic_tokens = model.to_str_tokens(arithmetic_tokens[vector_logits[arithmetic_tokens].view(-1).topk(v_tokens, largest=False).indices], prepend_bos=False)\n",
    "    \n",
    "    # Create the 2-D activation pattern of the neuron. Each cell in index (op1, op2) is the activation of the neuron for the prompt containing op1 and op2 (for the operator used in later cells)\n",
    "    activation_img = torch.zeros((max_op - min_op, max_op - min_op))\n",
    "    for i, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "        activation_img[op1 - min_op, op2 - min_op] = prompts_activations[(layer, neuron)][i]\n",
    "\n",
    "    # Present all information\n",
    "    print(f'Neuron {neuron}:')\n",
    "    imshow(activation_img, x=list(range(min_op, max_op)), y=list(range(min_op, max_op)), labels={'x': 'Operand2', 'y': 'Operand1'}, width=600,\n",
    "        title=f'Neuron {neuron} activations in MLP {layer} as function of operands')\n",
    "    topk_op1_op2_pairs, bottomk_op1_op2_pairs =  _get_top_op1_op2_indices(layer, neuron, prompts_activations, top_k=50), \\\n",
    "                                                 _get_top_op1_op2_indices(layer, neuron, prompts_activations, top_k=50, is_top=False)\n",
    "    print(\"Top 50 op1,op2 values in activation map: \", topk_op1_op2_pairs)\n",
    "    print(\"Top results: \", [safe_eval(f\"{op1}{OPERATORS[operator_idx]}{op2}\") for (op1, op2) in topk_op1_op2_pairs])\n",
    "    if not use_kv_maps:\n",
    "        print(\"Bottom 50 op1,op2 values in activation map: \", bottomk_op1_op2_pairs)\n",
    "        print(\"Bottom results: \", [safe_eval(f\"{op1}{OPERATORS[operator_idx]}{op2}\") for (op1, op2) in bottomk_op1_op2_pairs])\n",
    "    if not use_kv_maps:\n",
    "        print(f'Top arithmetic {v_tokens} tokens: {topk_arithmetic_tokens}')\n",
    "        print(f'Bottom arithmetic {v_tokens} tokens: {bottomk_arithmetic_tokens}')\n",
    "    print(sorted(rev_heuristic_classes[(layer, neuron)], key=lambda x:x[1], reverse=True)) # Show the heuristic matching scores of this neuron\n",
    "\n",
    "\n",
    "def reverse_heuristic_dictionary(d):\n",
    "    \"\"\"\n",
    "    Turn the heuristic classes list to a reversed dictionary of neuron->(heuristic_name, score)\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for heuristic, layer_neuron_scores in d.items():\n",
    "        for lns in layer_neuron_scores:\n",
    "            result.setdefault(lns[:2], []).append((heuristic, lns[2]))\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_top_op1_op2_indices(layer, neuron_idx, prompts_activations, top_k=None, is_top=True):\n",
    "    \"\"\"\n",
    "    Get, from a specific neurons activations, the highest (or lowest) activating pairs of (op1, op2) values.\n",
    "    \"\"\"\n",
    "    activation_map = prompts_activations[(layer, neuron_idx)]\n",
    "    if top_k is None:\n",
    "        top_k = len(activation_map)\n",
    "    top_op1_op2_pairs = op1_op2_pairs[activation_map.topk(top_k, largest=is_top).indices.cpu().numpy()].tolist()\n",
    "    return top_op1_op2_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the activations of top neurons in each layer for a specific operator.\n",
    "# This cell must be run for the other heuristic analysis cells to work.\n",
    "\n",
    "# Settings\n",
    "operator_idx = 0\n",
    "topk_neurons_per_layer = 200\n",
    "min_op = 1 if operator_idx == 3 else 0\n",
    "max_op = 50\n",
    "\n",
    "# Create an ORDERED list of all valid (op1, op2) pairs for the operator\n",
    "op1_op2_pairs = torch.tensor(sorted([(op1, op2) for op1 in range(min_op, max_op) for op2 in _get_operand_range(OPERATORS[operator_idx], op1, min_op, max_op, get_model_consts(model_name).max_single_token)]))\n",
    "prompts = [f'{op1}{OPERATORS[operator_idx]}{op2}=' for (op1, op2) in op1_op2_pairs]\n",
    "\n",
    "# Get the numerical tokens in the model's vocabulary\n",
    "arithmetic_labels = [label for label in model.tokenizer.vocab if _is_number(label.strip(\" \"), is_int=True)]\n",
    "arithmetic_tokens = model.to_tokens(arithmetic_labels, prepend_bos=False).view(-1)\n",
    "\n",
    "# Create a list of heuristical neurons in the relevant layers (16 - 31 for Llama3-8B)\n",
    "neuron_importance_scores = get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=-1)\n",
    "heuristic_neurons = []\n",
    "for layer in range(get_model_consts(model_name).first_heuristics_layer, model.cfg.n_layers):\n",
    "    heuristic_neurons += [(layer, neuron) for neuron in neuron_importance_scores[layer].topk(topk_neurons_per_layer).indices.tolist()]\n",
    "\n",
    "# Calculate k (key) prompt activations\n",
    "k_prompts_activations = generate_activations(model, prompts, [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)], pos=-1)\n",
    "k_prompts_activations = {(layer, neuron): k_prompts_activations[layer][:, neuron] for (layer, neuron) in heuristic_neurons}\n",
    "\n",
    "# Calculate kv (key-value) prompt activations by multiplying the key activations with the value vector logits\n",
    "kv_prompts_activations = {}\n",
    "results_for_all_pairs = [str(safe_eval(f'{op1}{OPERATORS[operator_idx]}{op2}')) for (op1, op2) in op1_op2_pairs]\n",
    "results_for_all_pairs_labels = model.to_tokens(results_for_all_pairs, prepend_bos=False).view(-1)\n",
    "for (layer, neuron) in tqdm(heuristic_neurons):\n",
    "    v_vector_logits = (model.blocks[layer].mlp.W_out[neuron] @ model.W_U)\n",
    "    logits_for_all_pairs = v_vector_logits[results_for_all_pairs_labels].cpu()\n",
    "    kv_prompts_activations[(layer, neuron)] = k_prompts_activations[(layer, neuron)] * logits_for_all_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sepearating heuristics to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep to make next cells run faster (top and bottom results are cached)\n",
    "\n",
    "heuristic_datas = []\n",
    "for use_kv_maps in [True, False]:\n",
    "    prompts_activations = kv_prompts_activations if use_kv_maps else k_prompts_activations\n",
    "    top_op1_op2_indices = {(layer, neuron): _get_top_op1_op2_indices(layer, neuron, prompts_activations, is_top=True) for (layer, neuron) in heuristic_neurons}\n",
    "    top_results = {}\n",
    "    for (layer, neuron) in tqdm(top_op1_op2_indices.keys()):\n",
    "        top_results[(layer, neuron)] = [safe_eval(f\"{op1}{OPERATORS[operator_idx]}{op2}\") for (op1, op2) in top_op1_op2_indices[(layer, neuron)]]\n",
    "        assert all([0 <= result <= get_model_consts(model_name).max_single_token for result in top_results[(layer, neuron)]])\n",
    "\n",
    "    # Create the object containing all relevant data for heuristic analysis. This object is passed to the heuristic analysis functions.\n",
    "    heuristic_data = HeuristicAnalysisData()\n",
    "    heuristic_data.also_check_bottom_results = not use_kv_maps\n",
    "    heuristic_data.op1_op2_pairs = op1_op2_pairs\n",
    "    heuristic_data.top_op1_op2_indices = top_op1_op2_indices\n",
    "    heuristic_data.top_results = top_results\n",
    "    heuristic_data.max_op = max_op\n",
    "    heuristic_data.max_single_token = get_model_consts(model_name).max_single_token\n",
    "    heuristic_data.operator_idx = operator_idx\n",
    "    heuristic_data.k_per_heuristic_cache = {}\n",
    "    heuristic_datas.append(heuristic_data)\n",
    "\n",
    "kv_heuristic_data, k_heuristic_data = heuristic_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the neuron to heuristic classification process.\n",
    "\n",
    "use_kv_maps = False\n",
    "if use_kv_maps:\n",
    "    heuristic_data = kv_heuristic_data\n",
    "else:\n",
    "    heuristic_data = k_heuristic_data\n",
    "heuristic_classes = classify_heuristic_neurons(heuristic_neurons, heuristic_data)\n",
    "torch.save(heuristic_classes, f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict_{\"KV\" if use_kv_maps else \"K\"}_maps.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-calculated heuristic classes to neurons dictionary for a specific operator.\n",
    "\n",
    "operator_idx = 0\n",
    "\n",
    "MATCH_THRESHOLD = 0.6\n",
    "\n",
    "heuristic_classes = load_heuristic_classes(f'./data/{model_name}', operator_idx, neuron_activations_type=\"HYBRID\") # HYBRID means that direct heuristics are classified using the key-value maps, and indirect heuristics are classified using the key maps\n",
    "heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    "\n",
    "# Some extra prep for later presentation\n",
    "classified_neurons = [(l, n) for (l, n, s) in sum(heuristic_classes.values(), [])]\n",
    "print(f\"Classified neurons: {len(classified_neurons)} (Unique: {len(set(classified_neurons))})\")\n",
    "unclassified_neurons = [(l, n) for (l, n) in heuristic_neurons if (l, n) not in classified_neurons]\n",
    "rev_heuristic_classes = reverse_heuristic_dictionary(heuristic_classes)\n",
    "rev_heuristic_classes.update({(l, n): [] for (l, n) in unclassified_neurons})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing statistics regarding heuristic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a plot bar showing the amount of heuristics in each heuristics class, grouped by heuristic type, separated by layer\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def union_dict_values_by_regex(dictionary, patterns):\n",
    "    result_dict = {}\n",
    "    for pattern in patterns:\n",
    "        pattern_keys = [key for key in dictionary.keys() if re.search(pattern, key)]\n",
    "        result_dict[pattern] = sum([dictionary[key] for key in pattern_keys], [])\n",
    "    return result_dict\n",
    "\n",
    "operator_idx = 0\n",
    "MATCH_THRESHOLD = 0.6\n",
    "heuristic_classes = load_heuristic_classes(f'./data/{model_name}', operator_idx, \"HYBRID\")\n",
    "heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    "\n",
    "heuristic_name_patterns = [r\"op\\d_\\d+mod\\d+\", r\"both_operands_\\d+mod\\d+\", r\"result_\\d+mod\\d+\", \n",
    "                           r\"op\\d_region_\\d+_\\d+\", r\"both_operands_region_\\d+_\\d+\",\tr\"result_region_\\d+_\\d+\", \n",
    "                           r\"same_operand\", \n",
    "                           r\"op\\d_value_\\d+\", r\"result_value_\\d+\", \n",
    "                           r\"op\\d_pattern_.*\", r\"result_pattern_.*\", \n",
    "                           r\"result_multi_value_.*\"]\n",
    "unified_heuristic_classes = union_dict_values_by_regex(heuristic_classes, heuristic_name_patterns)\n",
    "df = pd.DataFrame([(key, layer, count) for key, value in unified_heuristic_classes.items() for layer, count in Counter(layer for layer, _, _ in value).items()],\n",
    "                  columns=['group', 'layer', 'count'])\n",
    "fig = go.Figure()\n",
    "for layer in sorted(df['layer'].unique()):\n",
    "    layer_data = df[df['layer'] == layer]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=layer_data['group'],\n",
    "        y=layer_data['count'],\n",
    "        name=str(layer)\n",
    "    ))\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    xaxis={'title': 'Group'},\n",
    "    yaxis={'title': 'Count'},\n",
    "    title='Count by Heuristic Group and Layer'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire heuristic knockout experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for heuristic knockout experiment in the paper (section 4.2, first experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_deterministic(42)\n",
    "operator_idx = 0\n",
    "MATCH_THRESHOLD = 0.6\n",
    "ACTIVATION_MAP_TYPE = [\"KV\", \"K\", \"HYBRID\"][2]\n",
    "\n",
    "# Load heuristic classes\n",
    "heuristic_classes_unfiltered = load_heuristic_classes(f\"./data/{model_name}\", operator_idx, ACTIVATION_MAP_TYPE)\n",
    "min_op = 1 if operator_idx == 3 else 0\n",
    "\n",
    "# Run the heuristic ablation experiment\n",
    "heuristics_knockout_results = heuristic_class_knockout_experiment(heuristic_classes, \n",
    "                                                                  operator_idx, \n",
    "                                                                  large_prompts_and_answers, \n",
    "                                                                  model, \n",
    "                                                                  min_op, max_op,\n",
    "                                                                  get_model_consts(model_name).max_single_token,\n",
    "                                                                  heuristic_neuron_match_threshold=MATCH_THRESHOLD,\n",
    "                                                                  seed=42, \n",
    "                                                                  verbose=True)\n",
    "torch.save(heuristics_knockout_results, f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results_thres={MATCH_THRESHOLD}_{ACTIVATION_MAP_TYPE}_maps.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected hypothesis - the accuracy of prompts associated with an ablated heuristic (ablated related) should drop more than the accuracy of prompts not \n",
    "# associated with that heuristic (ablated unrelated).\n",
    "\n",
    "# This is an initial version of the figure presented in the paper, used for investigations.\n",
    "\n",
    "operator_idx = 0\n",
    "MIN_NEURONS_PER_HEURISTIC = 10\n",
    "MIN_SCORE_SUM_PER_HEURISTIC = 10\n",
    "MATCH_THRESHOLD = 0.55\n",
    "ACTIVATION_MAP_TYPE = [\"KV\", \"K\", \"HYBRID\"][2]\n",
    "\n",
    "heuristics_knockout_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results_thres={MATCH_THRESHOLD}_{ACTIVATION_MAP_TYPE}_maps.pt')\n",
    "heuristics_knockout_results = sorted(heuristics_knockout_results, key=lambda h: h.baseline_related - h.ablated_related, reverse=True)\n",
    "heuristics_knockout_results = [h for h in heuristics_knockout_results if \\\n",
    "                                len(h.ablated_neurons)>= MIN_NEURONS_PER_HEURISTIC and \n",
    "                                h.ablated_neuron_matching_score >= MIN_SCORE_SUM_PER_HEURISTIC]\n",
    "\n",
    "if ACTIVATION_MAP_TYPE == \"KV\":\n",
    "    # No point in looking at operand heuristics\n",
    "    heuristics_knockout_results = [h for h in heuristics_knockout_results if h.heuristic_name.startswith('result')]\n",
    "\n",
    "heuristics_knockout_results = [h for h in heuristics_knockout_results if not h.heuristic_name.startswith('result')]\n",
    "\n",
    "\n",
    "heuristic_names_to_test = [h.heuristic_name for h in heuristics_knockout_results]\n",
    "baseline_related = torch.tensor([h.baseline_related for h in heuristics_knockout_results])\n",
    "baseline_unrelated = torch.tensor([h.baseline_unrelated for h in heuristics_knockout_results])\n",
    "ablated_related = torch.tensor([h.ablated_related for h in heuristics_knockout_results])\n",
    "ablated_unrelated = torch.tensor([h.ablated_unrelated for h in heuristics_knockout_results])\n",
    "ablated_neurons_counts = torch.tensor([len(h.ablated_neurons) for h in heuristics_knockout_results])\n",
    "ablated_neuron_matching_scores = torch.tensor([h.ablated_neuron_matching_score for h in heuristics_knockout_results])\n",
    "\n",
    "show_all_lines = True\n",
    "        all_lines:\n",
    "    lines = [baseline_related, baseline_unrelated, ablated_related, ablated_unrelated]\n",
    "    line_titles = [\"Baseline related\", \"Baseline unrelated\", \"Ablated related\", \"Ablated unrelated\"]\n",
    "    line_colors = [\"blue\", \"red\", \"green\", \"purple\"]\n",
    "else:\n",
    "    lines = [baseline_related, ablated_related]\n",
    "    line_titles = [f\"baseline\", f\"ablated\"]\n",
    "    line_colors = [\"blue\", \"red\"]\n",
    "\n",
    "fig = multiple_lines(list(range(len(baseline_related))), lines, line_titles,\n",
    "               title=rf\"{OPERATOR_NAMES[operator_idx]} accuracy on related{' and unrelated prompts' if show_all_lines else ''}<br> before and after knockouts<br>\" + \n",
    "               f\"Sorted by knockout diff (On {ACTIVATION_MAP_TYPE} activation maps)\",\n",
    "               xaxis_title=\"Heuristic index\",\n",
    "               yaxis_title=\"Accuracy\",\n",
    "               hovertext=list(zip(heuristic_names_to_test, ablated_neurons_counts, ablated_neuron_matching_scores)),\n",
    "               show_fig=False,\n",
    "               width=500)\n",
    "\n",
    "for i, l in enumerate(lines):\n",
    "    fig.add_hline(y=l.mean(), line_dash=\"dash\", line_color=line_colors[i])\n",
    "\n",
    "\n",
    "# Add hovertext for the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knockout prompt-related heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for prompt-guided heuristic neurons knockout experiment in the paper (section 4.2, second experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this cell is to ablate neurons which are associated with a prompt, and see how it affects the model's accuracy on the prompt.\n",
    "# Our hypothesis is that ablating neurons that belong to heuristics associated with a prompt will lead to a higher drop in accuracy compared to ablating random neurons.\n",
    "# Failures can be explained by imperfect heuristics / misseing heuristic classes definitions.\n",
    "\n",
    "# Run across several seeds to get a better feel for the best amount of neurons to knock out per operator\n",
    "\n",
    "MATCH_THRESHOLD = 0.6\n",
    "neuron_hard_limits = range(0, 201, 5)\n",
    "seeds = [42]\n",
    "\n",
    "baseline_results = torch.zeros((len(OPERATORS), len(neuron_hard_limits), len(seeds)))\n",
    "ablated_results = torch.zeros((len(OPERATORS), len(neuron_hard_limits), len(seeds)))\n",
    "ablated_neuron_counts = torch.zeros((len(OPERATORS), len(neuron_hard_limits), len(seeds)))\n",
    "control_results = torch.zeros((len(OPERATORS), len(neuron_hard_limits), len(seeds)))\n",
    "\n",
    "for neuron_hard_limit_idx, neuron_hard_limit in enumerate(tqdm(neuron_hard_limits)):\n",
    "    for operator_idx in range(len(OPERATORS)):\n",
    "        neuron_importance_scores = get_neuron_importance_scores(operator_idx=operator_idx, pos=-1)\n",
    "        all_top_neurons = []\n",
    "        for layer in range(16, model.cfg.n_layers):\n",
    "            all_top_neurons += [(layer, neuron) for neuron in neuron_importance_scores[layer].topk(200).indices.tolist()]\n",
    "\n",
    "        for seed_idx, seed in enumerate(seeds):\n",
    "            set_deterministic(seed)\n",
    "            heuristic_classes = load_heuristic_classes(f'./data/{model_name}', operator_idx, \"HYBRID\")\n",
    "            heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()}\n",
    "            prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "            baseline, ablated, ablated_neuron_avg_count, control_ablated = prompt_knockout_experiment(heuristic_classes, \n",
    "                                                                                                      model, prompts_and_answers, \n",
    "                                                                                                      neuron_count_hard_limit_per_layer=neuron_hard_limit,\n",
    "                                                                                                      all_top_neurons=all_top_neurons,\n",
    "                                                                                                      metric_fn=model_accuracy)\n",
    "            baseline_results[operator_idx, neuron_hard_limit_idx, seed_idx] = baseline\n",
    "            ablated_results[operator_idx, neuron_hard_limit_idx, seed_idx] = ablated\n",
    "            ablated_neuron_counts[operator_idx, neuron_hard_limit_idx, seed_idx] = ablated_neuron_avg_count\n",
    "            control_results[operator_idx, neuron_hard_limit_idx, seed_idx] = control_ablated\n",
    "            print(f\"{neuron_hard_limit=}, {operator_idx=}, {seed=}, {baseline=}, {ablated=}, {ablated_neuron_avg_count=}, {control_ablated=}\")\n",
    "\n",
    "torch.save((neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results), f'./data/{model_name}/prompt_knockout_results_with_neuron_limits_per_layer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug failed heuristic knockouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_idx = 0\n",
    "MATCH_THRESHOLD = 0.55\n",
    "heuristic_classes = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_matches_dict_K_maps.pt')\n",
    "heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()} # Filter by threshold\n",
    "rev_heuristic_classes = reverse_heuristic_dictionary(heuristic_classes)\n",
    "\n",
    "print(get_relevant_prompts(\"op2_pattern_.8.\", operator_idx, min_op, max_op))\n",
    "\n",
    "neurons_to_analyze = heuristic_classes[f\"op2_pattern_.8.\"][:10]\n",
    "for n in neurons_to_analyze:\n",
    "    layer, neuron = n[0], n[1]\n",
    "    present_neuron(layer, neuron, use_kv_maps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt better method for pattern identification in the maps \n",
    "\n",
    "layer, neuron = 16, 2512\n",
    "# present_neuron(layer, neuron, use_kv_maps=False)\n",
    "\n",
    "def is_pattern_neuron_new(layer, neuron, pattern, op_index=1, use_kv_maps=False):\n",
    "    # Get op1, op2 pairs relevant to the pattern\n",
    "    relevant_pair_indices = [i for (i, (op1, op2)) in enumerate(op1_op2_pairs) if re.match(f\"^{pattern}$\", str((op1 if op_index == 1 else op2).item()).zfill(3))]\n",
    "    \n",
    "    # Get the activations of the neuron for the relevant pairs\n",
    "    prompt_activations = kv_prompts_activations[(layer, neuron)] if use_kv_maps else k_prompts_activations[(layer, neuron)]\n",
    "    relevant_activations = prompt_activations[relevant_pair_indices]\n",
    "    \n",
    "\n",
    "is_pattern_neuron_new(layer, neuron, '.8.'), is_pattern_neuron_new(layer, neuron, '.3.')#, get_periodic_patterns(layer, neuron, heuristic_analysis_data, op_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_heuristics = [(18, 391), (18, 13662), (19, 1064)] # WAVE HEURISTICS\n",
    "non_wave_heuristics = [(19, 477), (18, 4040)]\n",
    "\n",
    "from pywt import wavedec, waverec, threshold\n",
    "from scipy import signal\n",
    "\n",
    "def get_fft_frequencies(tensor, sample_rate=1.0):\n",
    "        # Ensure the tensor is on CPU and convert to numpy array\n",
    "        if tensor.is_cuda:\n",
    "            tensor = tensor.cpu()\n",
    "        signal = tensor.numpy()\n",
    "\n",
    "        # Compute the FFT\n",
    "        fft_result = torch.fft.fft(tensor)\n",
    "        \n",
    "        # Get the magnitude spectrum\n",
    "        magnitude_spectrum = torch.abs(fft_result)\n",
    "        \n",
    "        # Compute the frequencies\n",
    "        n = len(signal)\n",
    "        freq = np.fft.fftfreq(n, d=1/sample_rate)\n",
    "        \n",
    "        return freq, magnitude_spectrum.numpy()\n",
    "\n",
    "def detect_variable_oscillation(y, noise_threshold=12.0, min_peaks=3):\n",
    "    # Denoise the signal using wavelet transform\n",
    "    coeffs = wavedec(y, 'db4', level=2)\n",
    "    coeffs[1:] = [threshold(i, value=noise_threshold*max(i), mode='soft') for i in coeffs[1:]]\n",
    "    y_denoised = waverec(coeffs, 'db4')\n",
    "    line(y_denoised)\n",
    "    \n",
    "    # Find peaks and troughs\n",
    "    peaks, _ = signal.find_peaks(y_denoised)\n",
    "    troughs, _ = signal.find_peaks(-y_denoised)\n",
    "\n",
    "    # peak_distances = np.diff(peaks)\n",
    "    peak_distance_relations = peaks[1:] / peaks[:-1]\n",
    "    print(peak_distance_relations)\n",
    "        \n",
    "# op2_value = 13 # random\n",
    "# values = prompts_activations[(layer, neuron)][(op1_op2_pairs[:, 1] == op2_value).nonzero()].view(-1)\n",
    "# line(values)\n",
    "# frequencies, magnitudes = get_fft_frequencies(values)\n",
    "# frequencies = frequencies[:len(frequencies) // 2]\n",
    "# magnitudes = magnitudes[:len(magnitudes) // 2]\n",
    "# line(magnitudes, x=frequencies)\n",
    "# threshold = 0.5 * magnitudes.max()\n",
    "# dominant_freq_indices = np.where(magnitudes > threshold)[0]\n",
    "# dominant_frequencies = frequencies[dominant_freq_indices]\n",
    "# dominant_frequencies\n",
    "# print(frequencies[magnitudes.argmax()].item() != 0)\n",
    "# if frequencies[magnitudes.argmax()].item() != 0:\n",
    "#     print(layer, neuron)\n",
    "\n",
    "# peaks = signal.find_peaks(values, height=values.max().item() / 2, distance=20)\n",
    "# peaks = signal.find_peaks_cwt(values, widths=5)\n",
    "# print(len(peaks), peaks)\n",
    "from visualization_utils import line\n",
    "for l, n in wave_heuristics + non_wave_heuristics:\n",
    "    op2_value = 13\n",
    "    values = k_prompts_activations[(l, n)][(op1_op2_pairs[:, 1] == op2_value).nonzero()].view(-1)\n",
    "    line(values)\n",
    "    detect_variable_oscillation(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for indirect heuristics in layer < 16 as well\n",
    "\n",
    "operator_idx = 0\n",
    "topk_neurons_per_layer = 200\n",
    "min_op = 1 if operator_idx == 3 else 0\n",
    "op1_op2_pairs = torch.tensor(sorted([(op1, op2) for op1 in range(min_op, max_op) for op2 in _get_operand_range(OPERATORS[operator_idx], op1, min_op, max_op, LLAMA3_8B_CONSTS.max_single_token)]))\n",
    "prompts = [f'{op1}{OPERATORS[operator_idx]}{op2}=' for (op1, op2) in op1_op2_pairs]\n",
    "arithmetic_labels = [label for label in model.tokenizer.vocab if _is_number(label.strip(\" \"), is_int=True)]\n",
    "arithmetic_tokens = model.to_tokens(arithmetic_labels, prepend_bos=False).view(-1)\n",
    "\n",
    "neuron_importance_scores = get_neuron_importance_scores(operator_idx=operator_idx, pos=-1)\n",
    "heuristic_neurons = []\n",
    "for layer in range(0, model.cfg.n_layers):\n",
    "    heuristic_neurons += [(layer, neuron) for neuron in neuron_importance_scores[layer].topk(topk_neurons_per_layer).indices.tolist()]\n",
    "\n",
    "# Calculate k (key) prompt activations\n",
    "k_prompts_activations = generate_activations(model, prompts, [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)], pos=-1)\n",
    "k_prompts_activations = {(layer, neuron): k_prompts_activations[layer][:, neuron] for (layer, neuron) in heuristic_neurons}\n",
    "\n",
    "# Calculate kv (key-value) prompt activations by multiplying the key activations with the value vector logits\n",
    "kv_prompts_activations = {}\n",
    "results_for_all_pairs = [str(safe_eval(f'{op1}{OPERATORS[operator_idx]}{op2}')) for (op1, op2) in op1_op2_pairs]\n",
    "results_for_all_pairs_labels = model.to_tokens(results_for_all_pairs, prepend_bos=False).view(-1)\n",
    "for (layer, neuron) in tqdm(heuristic_neurons):\n",
    "    v_vector_logits = (model.blocks[layer].mlp.W_out[neuron] @ model.W_U)\n",
    "    logits_for_all_pairs = v_vector_logits[results_for_all_pairs_labels].cpu()\n",
    "    kv_prompts_activations[(layer, neuron)] = k_prompts_activations[(layer, neuron)] * logits_for_all_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating failure modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation with the effect of heuristics on correctly-completed or incorrectly-completed prompts.\n",
    "# This is the code behind section 4.3.\n",
    "\n",
    "def get_key_activation(prompt, layer, neuron):\n",
    "    \"\"\"\n",
    "    Find the activation of the key neuron (without considering any value vector logits) for a specific prompt.\n",
    "    \"\"\"\n",
    "    op1, op2 = map(int, re.findall(r\"\\d+\", prompt))\n",
    "    prompt_index = ((op1_op2_pairs[:, 0] == op1) & (op1_op2_pairs[:, 1] == op2)).nonzero().item()\n",
    "    return k_prompts_activations[(layer, neuron)][prompt_index]\n",
    "\n",
    "\n",
    "def get_logit_of_correct_answer_from_neuron(prompt, layer, neuron):\n",
    "    \"\"\"\n",
    "    Get the logit contribution of a specific neuron for a prompt.\n",
    "    The logit contribution is based both on the activation of the neuron for the prompt, as well as the logit of the correct answer in the neuron's V vector.\n",
    "    \"\"\"\n",
    "    # Find the activation of the neuron for the given prompt\n",
    "    op1, op2 = map(int, re.findall(r\"\\d+\", prompt))\n",
    "    prompt_index = ((op1_op2_pairs[:, 0] == op1) & (op1_op2_pairs[:, 1] == op2)).nonzero().item()\n",
    "    return kv_prompts_activations[(layer, neuron)][prompt_index]\n",
    "\n",
    "\n",
    "MATCH_THRESHOLD = 0.6\n",
    "heuristic_classes = load_heuristic_classes(f'./data/{model_name}', operator_idx, \"HYBRID\")\n",
    "heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in heuristic_classes.items()}\n",
    "\n",
    "\n",
    "def analyze_prompt_heuristic_properties(prompts):\n",
    "    \"\"\"\n",
    "    Function to check various properties of the model's behavior on a set of prompts.\n",
    "    Some properties include - the number of neurons associated with each prompt (as described in the paper),\n",
    "        the total logit contribution of the associated neuron to the correct answer token (as described in the paper),\n",
    "        \n",
    "    \"\"\"\n",
    "    # key_activation_threshold = 0.05 # Magin number #1\n",
    "    logit_contrib_threshold = 0.05 # Magic number #2\n",
    "\n",
    "    avg_associated_neuron_count = 0\n",
    "    avg_key_activation = 0\n",
    "    avg_high_contrib_neuron_count = 0\n",
    "    avg_matching_score, avg_filtered_matching_score = 0, 0\n",
    "    logit_contribs = {}\n",
    "    for prompt in tqdm(prompts):\n",
    "        associated_neurons = get_neurons_associated_with_prompt(prompt)\n",
    "        avg_associated_neuron_count += len(associated_neurons)\n",
    "        logit_contribs[prompt] = torch.stack([get_logit_of_correct_answer_from_neuron(prompt, layer, neuron) for (layer, neuron) in associated_neurons])\n",
    "        avg_key_activation += sum([get_key_activation(prompt, layer, neuron).abs().item() for (layer, neuron) in associated_neurons])\n",
    "        avg_high_contrib_neuron_count += (logit_contribs[prompt] > logit_contrib_threshold).sum().item()\n",
    "\n",
    "        all_heuristic_scores, high_contrib_heuristic_scores = [], []\n",
    "        for i, (layer, neuron) in enumerate(associated_neurons):\n",
    "            neuron_with_high_contrib = logit_contribs[prompt][i] > logit_contrib_threshold\n",
    "            for heuristic_name, score in associated_neurons[(layer, neuron)]:\n",
    "                all_heuristic_scores.append(score)\n",
    "                if neuron_with_high_contrib:\n",
    "                    high_contrib_heuristic_scores.append(score)\n",
    "        avg_matching_score += sum(all_heuristic_scores) / len(all_heuristic_scores)\n",
    "        avg_filtered_matching_score += sum(high_contrib_heuristic_scores) / len(high_contrib_heuristic_scores)\n",
    "\n",
    "    avg_associated_neuron_count /= len(prompts_and_answers)\n",
    "    avg_key_activation /= len(prompts_and_answers)\n",
    "    avg_high_contrib_neuron_count /= len(prompts_and_answers)\n",
    "    avg_matching_score /= len(prompts_and_answers)\n",
    "    avg_filtered_matching_score /= len(prompts_and_answers)\n",
    "    print(f\"Average number of neurons that implement heuristics associated with the prompts: {avg_associated_neuron_count}\")\n",
    "    # print(f\"Average key activation: {avg_key_activation}\")\n",
    "    print(f\"Average number of neurons with high logit contrib: {avg_high_contrib_neuron_count}\")\n",
    "    # print(f\"Average heuristic matching score of associated neurons: {avg_matching_score}\")\n",
    "    # print(f\"Average heuristic matching score of associated neurons with high logit contrib: {avg_filtered_matching_score}\")\n",
    "    \n",
    "    return logit_contribs\n",
    "\n",
    "contribs = {}\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    print(\"Correct prompts\")\n",
    "    correct_prompts = separate_prompts_and_answers(correct_prompts_and_answers[operator_idx])[0]\n",
    "    logit_contribs = analyze_prompt_heuristic_properties(correct_prompts)\n",
    "\n",
    "    print(\"Incorrect prompts\")\n",
    "    incorrect_prompts = random.sample(separate_prompts_and_answers(incorrect_prompts_and_answers[operator_idx])[0], len(correct_prompts))\n",
    "    incorrect_logit_contribs = analyze_prompt_heuristic_properties(incorrect_prompts)\n",
    "\n",
    "    contribs[OPERATORS[operator_idx]] = (logit_contribs, incorrect_logit_contribs)\n",
    "torch.save(contribs, f'./data/{model_name}/correct_and_incorrect_prompts_heuristic_logit_contributions.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save activation patterns (for many figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Before running this cell you need to run the code from the cells above to generate the activation maps for the relevant operator first\n",
    "\n",
    "# Generate many activation pattern visualizations to use in later figures\n",
    "\n",
    "NEURONS_TO_VISUALIZE_PER_LAYER = 50\n",
    "neuron_vis_path = f\"./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_neuron_visualizations\"\n",
    "neuron_importance_scores = get_neuron_importance_scores(operator_idx=operator_idx)\n",
    "for activation_map_type in [\"KV\", \"K\"]:\n",
    "    for layer in range(LLAMA3_8B_CONSTS.first_heuristics_layer, model.cfg.n_layers):\n",
    "        top_neurons = neuron_importance_scores[layer].topk(NEURONS_TO_VISUALIZE_PER_LAYER).indices.tolist()\n",
    "        for neuron in top_neurons:\n",
    "            neuron_vis_path = f\"./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_neuron_visualizations/mlp{layer}_neuron{neuron}_{activation_map_type}_map.png\"\n",
    "            if not os.path.exists(neuron_vis_path):\n",
    "                activations = k_prompts_activations if activation_map_type == \"K\" else kv_prompts_activations\n",
    "                activation_img = torch.zeros((max_op - min_op, max_op - min_op))\n",
    "                for i, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "                    activation_img[op1 - min_op, op2 - min_op] = activations[(layer, neuron)][i]\n",
    "                fig = px.imshow(activation_img, x=list(range(min_op, max_op)), y=list(range(min_op, max_op)), \n",
    "                                labels={'x': 'Operand2', 'y': 'Operand1'}, width=600, \n",
    "                                # title=f'MLP{layer}#{neuron} {activation_map_type} activation map as function of operands ({OPERATOR_NAMES[operator_idx]})',\n",
    "                                color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\")\n",
    "                fig.update_xaxes(\n",
    "                    title_font=dict(size=20, family='Arial', color='black'),\n",
    "                    tickfont=dict(size=14, family='Arial', color='black'),\n",
    "                    tickvals=None\n",
    "                )\n",
    "                fig.update_yaxes(\n",
    "                    title_font=dict(size=20, family='Arial', color='black'),\n",
    "                    tickfont=dict(size=14, family='Arial', color='black'),\n",
    "                    tickvals=None\n",
    "                )\n",
    "                os.makedirs(os.path.dirname(neuron_vis_path), exist_ok=True)\n",
    "                fig.write_image(neuron_vis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic types figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_increase = 0 # size increase across all fonts\n",
    "layer_neurons = [(16, 6337), (0, 0), (17, 5628), (27, 9413), (0, 0)]\n",
    "heuristic_titles = [\"Op1 Range\", \"Op2 Modulo\", \"Op1 == Op2\", \"Result Range\", \"Result Pattern\"]\n",
    "assert len(layer_neurons) == len(heuristic_titles)\n",
    "\n",
    "if 'activation_imgs' not in locals():\n",
    "    max_op, min_op = 300, 0\n",
    "    activation_imgs = torch.zeros(len(layer_neurons), max_op - min_op, max_op - min_op)\n",
    "    for i, (layer, neuron) in enumerate(layer_neurons):\n",
    "        if i == 1:\n",
    "            # Hacky way to visualize this type of heuristic so it will be visible in the figure\n",
    "            for j, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "                activation_imgs[i, op1 - min_op, op2 - min_op] = random.normalvariate(0.8, 0.2) if op2 % 9 == 2 else random.normalvariate(0.1, 0.05)\n",
    "        elif i == len(layer_neurons) - 1:\n",
    "            # Hacky way to visualize this type of heuristic so it will be visible in the figure\n",
    "            for j, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "                activation_imgs[i, op1 - min_op, op2 - min_op] = random.normalvariate(0.8, 0.2) if (((op1 + op2) % 100) // 10) == 2 else random.normalvariate(0.1, 0.05)\n",
    "        else:\n",
    "            use_kv_maps = 'result' in heuristic_titles[i].lower()\n",
    "            prompts_activations = kv_prompts_activations if use_kv_maps else k_prompts_activations\n",
    "            for j, (op1, op2) in enumerate(op1_op2_pairs):\n",
    "                activation_imgs[i, op1 - min_op, op2 - min_op] = prompts_activations[(layer, neuron)][j]\n",
    "        activation_imgs[i] = (activation_imgs[i] - activation_imgs[i].min()) / (activation_imgs[i].max() - activation_imgs[i].min())\n",
    "\n",
    "main_fig = make_subplots(rows=1, cols=len(layer_neurons), shared_yaxes=True, horizontal_spacing=0.02)\n",
    "    \n",
    "for i, (layer, neuron) in enumerate(layer_neurons):\n",
    "    fig = px.imshow(activation_imgs[i], \n",
    "                    # x=list(range(min_op, max_op)), \n",
    "                    # y=list(range(min_op, max_op)), \n",
    "                    # labels={'x': 'Operand2', 'y': 'Operand1'},\n",
    "                    color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\")\n",
    "    fig.update_layout(showlegend=False, title=None)\n",
    "    main_fig.add_trace(fig.data[0], row=1, col=i + 1)\n",
    "    main_fig.update_yaxes(row=1, col=i + 1, scaleanchor='x') # Invert y axis and make it same size as x axis\n",
    "    if i == 0:\n",
    "        main_fig.update_yaxes(title=dict(standoff=0, text='Operand 1', font=dict(size=17 + size_increase)), row=1, col=i + 1, tickvals=[], tickfont=dict(size=14 + size_increase))\n",
    "    main_fig.update_xaxes(row=1, col=i + 1, tickvals=[], tickfont=dict(size=14 + size_increase))\n",
    "    main_fig.update(layout_coloraxis_showscale=False)\n",
    "    \n",
    "    main_fig.add_annotation(\n",
    "        text=f\"<b>{heuristic_titles[i]}</b>\",  # Title from heuristic_titles\n",
    "        x=i / len(layer_neurons) + (1 / (2 * len(layer_neurons))),  # Center the title under each subfigure\n",
    "        y=1.15,\n",
    "        xref=\"paper\", \n",
    "        yref=\"paper\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=17 + size_increase),\n",
    "        xanchor=\"center\"\n",
    "    )\n",
    "\n",
    "    main_fig.add_annotation(\n",
    "        text=\"Operand 2\",\n",
    "        x=i / len(layer_neurons) + (1 / (2 * len(layer_neurons))),  # Center the title under each subfigure\n",
    "        y=-0.15,\n",
    "        xref=\"paper\", \n",
    "        yref=\"paper\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=17 + size_increase),\n",
    "        xanchor=\"center\"\n",
    "    )\n",
    "\n",
    "main_fig.update_layout(\n",
    "    width=800,\n",
    "    height=180,\n",
    "    margin=dict(t=20, b=20, r=0, l=30),\n",
    "    coloraxis=dict(colorscale=\"RdBu\", cmin=-1, cmax=1)\n",
    ")\n",
    "main_fig.show()\n",
    "\n",
    "pio.write_image(main_fig, \"./figs/heuristic_type_examples.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localization figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localization results figure (Using activation patching results)\n",
    "\n",
    "model_name = \"llama3-8b\"\n",
    "attn_maps_sum_over_positions = False # If False, only the last position IE is presented\n",
    "\n",
    "ie_maps = torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt')\n",
    "\n",
    "# Average across seeds\n",
    "summed_seed_ie_maps = {}\n",
    "op_idxs = [0, 1, 2, 3]\n",
    "seeds = set([])\n",
    "for op_idx, pos, seed in ie_maps.keys():\n",
    "    seeds.add(seed)\n",
    "    if (op_idx, pos) not in summed_seed_ie_maps:\n",
    "        summed_seed_ie_maps[(op_idx, pos)] = ie_maps[(op_idx, pos, seed)]\n",
    "    else:\n",
    "        summed_seed_ie_maps[(op_idx, pos)] += ie_maps[(op_idx, pos, seed)]\n",
    "ie_maps = {k: v / len(seeds) for (k, v) in summed_seed_ie_maps.items()}\n",
    "\n",
    "# Average across operators\n",
    "ie_maps = {pos: torch.stack([ie_maps[(op_idx, pos)] for op_idx in op_idxs]).mean(dim=0) for pos in POSITIONS}\n",
    "\n",
    "# Tensorify\n",
    "ie_maps = torch.stack([ie_maps[pos] for pos in POSITIONS]) # pos, Layers, heads+mlp\n",
    "ie_maps = np.log1p(ie_maps)\n",
    "\n",
    "attn_maps, mlp_maps = ie_maps[:, :, :-1], ie_maps[:, :, -1]\n",
    "if attn_maps_sum_over_positions:\n",
    "    attn_maps = attn_maps.sum(dim=0) # Sum effect from all positions\n",
    "else:\n",
    "    attn_maps = attn_maps[-1] # Take only last position\n",
    "mlp_maps = mlp_maps.T\n",
    "\n",
    "\n",
    "# Find the global min and max values for mutual scaling (for both MLP and ATTN subfigures)\n",
    "global_min = min(attn_maps.min(), mlp_maps.min()).item()\n",
    "global_max = max(attn_maps.max(), mlp_maps.max()).item()\n",
    "\n",
    "# Create subplots\n",
    "attn_title = \"Attention Heads (Summed over positions)\" if attn_maps_sum_over_positions else \"Attention Heads (Last Position)\"\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[attn_title, \"MLPs\"], shared_yaxes=True, horizontal_spacing=0.02)\n",
    "\n",
    "# Add heatmaps to subplots\n",
    "fig.add_trace(go.Heatmap(z=attn_maps, coloraxis=\"coloraxis\", zsmooth=False), row=1, col=1)\n",
    "fig.add_trace(go.Heatmap(z=mlp_maps, coloraxis=\"coloraxis\", zsmooth=False), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title=dict(text=\"Attention Head\", font=dict(size=16), standoff=8), tickfont=dict(size=15), domain=[0, 0.7], row=1, col=1)\n",
    "fig.update_yaxes(title=dict(text=\"Layer\", font=dict(size=16), standoff=15), tickfont=dict(size=15), autorange=\"reversed\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title=dict(text=\"Position\", font=dict(size=16), standoff=8), tickfont=dict(size=15), domain=[0.8, 1.0], row=1, col=2)\n",
    "fig.update_yaxes(autorange=\"reversed\", row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Effect Map Per Attn Head / MLP\",\n",
    "        'x': 0.55, 'y': 0.98,\n",
    "        'font': dict(size=17)\n",
    "    },\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    "    height=200,\n",
    "    width=500,\n",
    "    coloraxis=dict(\n",
    "        colorscale='Blues',\n",
    "        cmin=global_min,\n",
    "        cmax=global_max,\n",
    "        colorbar=dict(\n",
    "            title=dict(text=\"log<br>scale\", font=dict(size=17)),\n",
    "            tickfont=dict(size=15),\n",
    "            thickness=20,\n",
    "            len=1.6,\n",
    "            yanchor=\"middle\",\n",
    "            y=0.65,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.layout.annotations[0].update(x=0.34, y=1.01, font=dict(size=16))\n",
    "fig.layout.annotations[1].update(x=0.90, y=1.01, font=dict(size=16))\n",
    "\n",
    "pio.write_image(fig, f'./figs/{model_name}_localization.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probing for answer figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing results\n",
    "\n",
    "probe_accs = torch.load(f'./data/{model_name}/probe_accs.pt')\n",
    "# Average across operators\n",
    "probe_accs = {pos_to_probe: torch.tensor([probe_accs[(operator_idx, pos_to_probe)] for operator_idx in range(len(OPERATORS))]).mean(dim=0) for pos_to_probe in POSITIONS}\n",
    "# Tensorify\n",
    "probe_accs_tensor = torch.stack([probe_accs[pos_to_probe] for pos_to_probe in POSITIONS])\n",
    "\n",
    "# Draw the figure\n",
    "fig = px.imshow(probe_accs_tensor, \n",
    "       y=['Operand1', 'Operator', 'Operand2', '='],\n",
    "       x=list(range(model.cfg.n_layers)),\n",
    "       width=350,\n",
    "       height=120,\n",
    "       zmin=0,\n",
    "       color_continuous_midpoint=0.0, color_continuous_scale=\"blues\"\n",
    ")\n",
    "fig.update_xaxes(title=dict(text=\"Layer\", standoff=5, font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.update_yaxes(title=dict(text=\"Position\", standoff=10, font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.update_layout(title_x=0.53, title_y=1.0, title_font=dict(size=17), margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig.update_coloraxes(colorbar=dict(len=1.2,  \n",
    "                                   thickness=20,  # Adjust thickness as needed\n",
    "                                   yanchor=\"middle\",  # Anchor colorbar to the middle\n",
    "                                   y=0.5))  # Center the colorbar vertically\n",
    "\n",
    "fig.show()\n",
    "pio.write_image(fig, f'./figs/probing_acc.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K MLP Neuron eval figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-k neurons localization results\n",
    "\n",
    "k_values = torch.tensor(sorted(list(range(0, model.cfg.d_mlp, 10)) + [model.cfg.d_mlp]))\n",
    "seeds = [42, 412, 32879, 123]\n",
    "results_file_path = f'./data/{model_name}/topk_neuron_faithfulness_evaluation_results.pt'\n",
    "\n",
    "# # GENERATE DATA\n",
    "# max_op = 300\n",
    "# mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "# if os.path.exists(results_file_path):\n",
    "#     faithfulness_per_k = torch.load(results_file_path)\n",
    "# else:\n",
    "#     faithfulness_per_k = {}\n",
    "# for operator_idx in [0,1,2,3]:\n",
    "#     for seed in seeds:\n",
    "#         if (operator_idx, seed) in faithfulness_per_k:\n",
    "#             print(f\"Found results file for {operator_idx=}, {seed=}\")\n",
    "#             continue\n",
    "#         set_deterministic(seed)\n",
    "#         prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "#         mlppost_neuron_scores = get_neuron_importance_scores( operator_idx=operator_idx, pos=-1) # Ranking neurons according to Attribution patching\n",
    "#        def build_circuit(operator_idx, mlp_top_neurons):      \n",
    "#            if operator_idx == 0:\n",
    "#                # Addition\n",
    "#                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 3), (5, 31), (14, 12), (15, 13), (16, 21)]]\n",
    "#            elif operator_idx == 1:\n",
    "#                # Subtraction\n",
    "#                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (13, 21), (13, 22), (14, 12), (15, 13), (16, 21)]]\n",
    "#            elif operator_idx == 2:\n",
    "#                # Multiplication\n",
    "#                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 30), (8, 15), (9, 26), (13, 18), (13, 21), (13, 22), \n",
    "#                                                                        (14, 12), (14, 13), (15, 8), (15, 13), (15, 14), (15, 15), (16, 3), \n",
    "#                                                                        (16, 21), (17, 24), (17, 26), (18, 16), (20, 2), (22, 1)]]\n",
    "#            elif operator_idx == 3:\n",
    "#                # Division\n",
    "#                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 31), (15, 13), (15, 14), (16, 21), (18, 16)]]\n",
    "#            partial_mlp_layers = list(range(get_model_consts(model_name).first_heuristics_layer, model.cfg.n_layers))\n",
    "#            full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers) if l not in partial_mlp_layers]\n",
    "#            partial_mlps = [Component('mlp_post', layer=l, neurons=mlp_top_neurons[l]) for l in partial_mlp_layers]    \n",
    "#            full_circuit = Circuit(model.cfg)\n",
    "#            for c in list(set(heads + full_mlps + partial_mlps)):\n",
    "#                full_circuit.add_component(c)\n",
    "#            return full_circuit\n",
    "#         faithfulness_per_k[(operator_idx, seed)] = torch.zeros((len(k_values),))\n",
    "#         for i, k in enumerate(k_values):\n",
    "#             mlp_top_neurons = {}\n",
    "#             for mlp in range(1, model.cfg.n_layers):\n",
    "#                 mlp_top_neurons[mlp] = mlppost_neuron_scores[mlp].topk(k).indices.tolist()\n",
    "#             full_circuit = build_circuit(operator_idx, mlp_top_neurons)\n",
    "#             faithfulness_per_k[(operator_idx, seed)][i] = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "#             print(k, faithfulness_per_k[(operator_idx, seed)][i].item())\n",
    "#         torch.save(faithfulness_per_k, results_file_path)\n",
    "\n",
    "\n",
    "# DRAW FIGURE\n",
    "colors = COLORBLIND_COLORS\n",
    "operator_labels = [\"+\", \"-\", \"\", \"\"]\n",
    "faithfulness_per_k = torch.load(results_file_path)\n",
    "# Average across seeds\n",
    "faithfulness_per_k = {operator_idx: torch.stack([faithfulness_per_k[(operator_idx, seed)] for seed in seeds]).mean(dim=0) for operator_idx in range(len(OPERATORS))}\n",
    "# Stack across operators\n",
    "faithfulness_per_k = torch.stack([faithfulness_per_k[operator_idx] for operator_idx in range(len(OPERATORS))])\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(len(OPERATORS)):\n",
    "    fig.add_trace(go.Scatter(x=k_values, y=faithfulness_per_k[i], mode='lines', name=operator_labels[i], line=dict(color=colors[i])))\n",
    "\n",
    "x_axis_percentages = [0.01, 0.1, 1]\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        type=\"log\",\n",
    "        tickvals=[percent * model.cfg.d_mlp for percent in x_axis_percentages],\n",
    "        ticktext=[f\"{int(percent * 100)}%\" for percent in x_axis_percentages],\n",
    "        tickfont=dict(size=15),\n",
    "        title=\"Neurons used Per Layer (%)\",\n",
    "        title_font=dict(size=16),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Faithfulness\",\n",
    "        tickfont=dict(size=15),\n",
    "        title_font=dict(size=16),\n",
    "        range=(0, 1.0)\n",
    "    ),\n",
    "    legend=dict(itemwidth=30, itemsizing='constant', yanchor=\"bottom\", \n",
    "                y=0.0, xanchor=\"center\", x=0.9, font=dict(size=16), bgcolor='rgba(0,0,0,0)'),\n",
    "    title=\"Faithfulness of using only top-k neurons\",\n",
    "    title_x=0.55, title_y=0.98, title_font=dict(size=16), \n",
    "    margin=dict(l=0, r=0, t=20, b=0), \n",
    "    width=400, height=200, \n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/faithfulness_topk_neurons.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of neurons in specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 17\n",
    "mlppost_neuron_scores = get_neuron_importance_scores(model, model_name, operator_idx=0, pos=-1)[layer] # Ranking neurons according to Attribution patching\n",
    "fig = go.Figure(data=go.Scatter(x=list(range(len(mlppost_neuron_scores))), y=mlppost_neuron_scores, \n",
    "                                mode=\"markers\",\n",
    "                                marker=dict(size=5, color=colors[0]), name=\"+\", showlegend=True))\n",
    "    \n",
    "fig.update_yaxes(title='Intervention Effect', range=[-0.02, 0.1], tickfont=dict(size=15), title_font=dict(size=16), tickvals=[0, 0.05])\n",
    "fig.update_xaxes(title=f'Neuron Index', tickfont=dict(size=15), title_font=dict(size=16))\n",
    "fig.update_layout(\n",
    "    title=f'Individual MLP Neuron Intervention Effects',\n",
    "    title_x=0.55,\n",
    "    title_y=0.98,\n",
    "    width=400,\n",
    "    height=200,\n",
    "    title_font=dict(size=16),\n",
    "    margin=dict(l=0, r=0, t=20, b=0),\n",
    "    legend=dict(itemwidth=30, itemsizing='constant', yanchor=\"bottom\", \n",
    "                y=-0.3, xanchor=\"center\", x=0.9, font=dict(size=16), bgcolor='rgba(0,0,0,0)'),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/mlp_neuron_intervention_effects_layer_{layer}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knockout figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablated_accs = []\n",
    "related_diff = []\n",
    "MATCH_THRESHOLD = 0.6\n",
    "ACTIVATION_MAP_TYPE = \"HYBRID\"\n",
    "for operator_idx in range(4):\n",
    "    heuristics_knockout_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results_thres={MATCH_THRESHOLD}_{ACTIVATION_MAP_TYPE}_maps.pt')\n",
    "    heuristics_knockout_results = sorted(heuristics_knockout_results, key=lambda h: h.baseline_related - h.ablated_related, reverse=True)\n",
    "    heuristics_knockout_results = [h for h in heuristics_knockout_results if \\\n",
    "                                    len(h.ablated_neurons)>= MIN_NEURONS_PER_HEURISTIC and \n",
    "                                    h.ablated_neuron_matching_score >= MIN_SCORE_SUM_PER_HEURISTIC]\n",
    "\n",
    "    if ACTIVATION_MAP_TYPE == \"KV\":\n",
    "        # No point in looking at operand heuristics\n",
    "        heuristics_knockout_results = [h for h in heuristics_knockout_results if h.heuristic_name.startswith('result')]\n",
    "\n",
    "    baseline_related = torch.tensor([h.baseline_related for h in heuristics_knockout_results])\n",
    "    ablated_related = torch.tensor([h.ablated_related for h in heuristics_knockout_results])\n",
    "    ablated_accs += ablated_related.cpu().tolist()\n",
    "    related_diff += (baseline_related - ablated_related).cpu().tolist()\n",
    "\n",
    "print(f\"Average ablated acc: {sum(ablated_accs) / len(ablated_accs)}\")\n",
    "print(f\"Average related diff: {sum(related_diff) / len(related_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure settings\n",
    "\n",
    "size_increase = 2 # font size increase across all fonts\n",
    "show_all_lines = True\n",
    "MIN_NEURONS_PER_HEURISTIC = 15\n",
    "MIN_SCORE_SUM_PER_HEURISTIC = 15\n",
    "MATCH_THRESHOLD = 0.55\n",
    "model_name = 'llama3-8b'\n",
    "colors = COLORBLIND_COLORS # px.colors.qualitative.Plotly\n",
    "ACTIVATION_MAP_TYPE = [\"KV\", \"K\", \"HYBRID\"][2]\n",
    "\n",
    "\n",
    "all_figs = []\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    heuristics_knockout_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[operator_idx]}_heuristic_ablation_results_thres={MATCH_THRESHOLD}_{ACTIVATION_MAP_TYPE}_maps.pt')\n",
    "    heuristics_knockout_results = sorted(heuristics_knockout_results, key=lambda h: h.baseline_related - h.ablated_related, reverse=True)\n",
    "    heuristics_knockout_results = [h for h in heuristics_knockout_results if \\\n",
    "                                    len(h.ablated_neurons)>= MIN_NEURONS_PER_HEURISTIC and \n",
    "                                    h.ablated_neuron_matching_score >= MIN_SCORE_SUM_PER_HEURISTIC]\n",
    "\n",
    "    if ACTIVATION_MAP_TYPE == \"KV\":\n",
    "        # No point in looking at operand heuristics\n",
    "        heuristics_knockout_results = [h for h in heuristics_knockout_results if h.heuristic_name.startswith('result')]\n",
    "\n",
    "    heuristic_names_to_test = [h.heuristic_name for h in heuristics_knockout_results]\n",
    "    baseline_related = torch.tensor([h.baseline_related for h in heuristics_knockout_results])\n",
    "    baseline_unrelated = torch.tensor([h.baseline_unrelated for h in heuristics_knockout_results])\n",
    "    ablated_related = torch.tensor([h.ablated_related for h in heuristics_knockout_results])\n",
    "    ablated_unrelated = torch.tensor([h.ablated_unrelated for h in heuristics_knockout_results])\n",
    "    ablated_neurons_counts = torch.tensor([len(h.ablated_neurons) for h in heuristics_knockout_results])\n",
    "    ablated_neuron_matching_scores = torch.tensor([h.ablated_neuron_matching_score for h in heuristics_knockout_results])\n",
    "\n",
    "    if show_all_lines:\n",
    "        lines = [ablated_related, ablated_unrelated]\n",
    "        line_titles = [f\"Effect of heuristic ablation on related prompts\", \"Effect of heuristic ablation on unrelated prompts\"]\n",
    "        line_colors = colors[:2]\n",
    "        # lines = [baseline_unrelated, baseline_related, ablated_unrelated, ablated_related]\n",
    "        # line_titles = [\"Baseline unrelated\", \"Baseline related\", \"Ablated unrelated\", \"Ablated related\"]\n",
    "        # line_colors = colors[:4]\n",
    "    else:\n",
    "        lines = [ablated_related, baseline_related]\n",
    "        line_titles = [f\"ablated\", \"baseline\"]\n",
    "        line_colors = [colors[0]] + [colors[2]]\n",
    "\n",
    "    fig = multiple_lines(list(range(len(baseline_related))), lines, line_titles,\n",
    "                title=rf\"{OPERATOR_NAMES[operator_idx]} accuracy on related{' and unrelated prompts' if show_all_lines else ''}<br> before and after knockouts<br>\" + \n",
    "                \"Sorted by knockout diff\",\n",
    "                xaxis_title=\"Heuristic index\",\n",
    "                yaxis_title=\"Accuracy\",\n",
    "                hovertext=list(zip(heuristic_names_to_test, ablated_neurons_counts, ablated_neuron_matching_scores)),\n",
    "                show_fig=False,\n",
    "                width=500)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        title=None\n",
    "    )\n",
    "\n",
    "    all_figs.append(fig)\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=4, shared_yaxes=True, horizontal_spacing=0.02)\n",
    "for i, subfig in enumerate(all_figs, start=1):\n",
    "    for j, trace in enumerate(subfig.data):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=trace.x, \n",
    "                y=trace.y, \n",
    "                name=trace.name, \n",
    "                mode='lines',\n",
    "                line=dict(color=line_colors[j]),\n",
    "                showlegend=i==1  # Only show legend for the first subplot\n",
    "            ),\n",
    "            row=1, \n",
    "            col=i\n",
    "        )\n",
    "        mean_value = f\"Mean: {trace.y.mean():.2f}\"\n",
    "        fig.add_annotation(\n",
    "            x=0.95*len(trace.x),  # Position near the right edge of the subplot\n",
    "            y=(j * 0.14),  # Stagger the text boxes (upper one higher)\n",
    "            xref=f'x{i}',  # Reference the x-axis of the current subplot\n",
    "            yref=f'y{i}',  # Reference the y-axis of the current subplot\n",
    "            text=mean_value,\n",
    "            showarrow=False,\n",
    "            font=dict(size=15+size_increase, color=colors[j]),\n",
    "            borderwidth=0,\n",
    "            xanchor='right',\n",
    "            yanchor='bottom'\n",
    "        )\n",
    "        # fig.add_hline(y=trace.y.mean(), line_dash=\"dash\", line_color=line_colors[j], row=1, col=i, name=f\"Mean {trace.name}\", showlegend=i == 1)\n",
    "    if i == 1:\n",
    "        fig.update_yaxes(title=dict(text='Accuracy', font=dict(size=17+size_increase)), row=1, col=i, tickfont=dict(size=15+size_increase))\n",
    "    fig.update_xaxes(title=dict(standoff=0, text=\"Heuristic index\", font=dict(size=17+size_increase)), row=1, col=i, \n",
    "                     tickvals=list(range(0, len(trace.y) - 2, int(len(trace.y) / 4.9))), tickfont=dict(size=15+size_increase))\n",
    "\n",
    "\n",
    "\n",
    "# Operator names subtitles\n",
    "for i, subtitle in enumerate(OPERATOR_NAMES):\n",
    "    fig.add_annotation(\n",
    "        x=(i + 1 - 0.5) / 4,  # This centers the subtitle over each subplot\n",
    "        y=1.0,  # Adjust this value to move subtitles up or down\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        text=subtitle[0].upper() + subtitle[1:],\n",
    "        showarrow=False,\n",
    "        font=dict(size=18+size_increase),\n",
    "        xanchor='center',\n",
    "        yanchor='bottom'\n",
    "    )\n",
    "    \n",
    "\n",
    "fig.update_layout(\n",
    "    height=250, width=1100, \n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=-0.25,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(size=16+size_increase)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=22, b=0)\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "pio.write_image(fig, f'./figs/knockout_{ACTIVATION_MAP_TYPE.lower()}_new.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt-guided knockout results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_layer = True\n",
    "operator_labels = ['+', '-', '', '']\n",
    "model_name = 'llama3-8b'\n",
    "neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/prompt_knockout_results_with_neuron_limits{\"_per_layer\" if per_layer else \"_choose_neurons_from_important\"}.pt')\n",
    "assert torch.all(baseline_results == 1)\n",
    "\n",
    "baseline_results = baseline_results.squeeze(-1)\n",
    "ablated_results = ablated_results.squeeze(-1)\n",
    "control_results = control_results.squeeze(-1)\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[neuron_hard_limits[0], neuron_hard_limits[-1]], y=[1, 1], mode='lines', name='Baseline', line=dict(color='black')))\n",
    "for i, op in enumerate(OPERATORS):\n",
    "    fig.add_trace(go.Scatter(x=neuron_hard_limits, y=ablated_results[i], mode='lines', name=f'{operator_labels[i]}',\n",
    "                            line=dict(color=colors[i])))\n",
    "    fig.add_trace(go.Scatter(x=neuron_hard_limits, y=control_results[i], mode='lines', name=f'', showlegend=True,\n",
    "                            line=dict(color=colors[i], dash='dash')))\n",
    "\n",
    "fig.update_yaxes(title=dict(text=\"Accuracy\", font=dict(size=17)), range=(0, 1.0), tickvals=[0.25, 0.5, 0.75, 1], tickfont=dict(size=15))\n",
    "fig.update_xaxes(title=dict(text=f'Ablated Neurons{\" (Per Layer)\" if per_layer else \"\"}', font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.update_layout(\n",
    "    legend_title='',\n",
    "    title_x=0.5, title_y=0.95,\n",
    "    margin=dict(l=0, r=5, t=30, b=0), \n",
    "    width=800,\n",
    "    height=250,\n",
    "    title=dict(\n",
    "        text=\"Prompt-guided heuristic knockout accuracies\",\n",
    "        font=dict(size=16),\n",
    "        xanchor='center',\n",
    "        yanchor='top'\n",
    "    ),\n",
    ")\n",
    "fig.show()\n",
    "pio.write_image(fig, f'./figs/prompt_knockout{\"_per_layer\" if per_layer else \"\"}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIFIED FOR llama3-8b and llama3-70b\n",
    "\n",
    "operator_labels = ['+', '-', '', '']\n",
    "colors = COLORBLIND_COLORS# px.colors.qualitative.Plotly\n",
    "\n",
    "def create_8b_figure():\n",
    "    model_name = 'llama3-8b'\n",
    "    neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/prompt_knockout_results_with_neuron_limits_per_layer.pt')\n",
    "    assert torch.all(baseline_results == 1)\n",
    "\n",
    "    baseline_results = baseline_results.squeeze(-1)\n",
    "    ablated_results = ablated_results.squeeze(-1)\n",
    "    control_results = control_results.squeeze(-1)\n",
    "\n",
    "    traces = []\n",
    "    # traces.append(go.Scatter(x=[neuron_hard_limits[0], neuron_hard_limits[-1]], y=[1, 1], mode='lines', name='', line=dict(color='grey')))\n",
    "    # traces.append(go.Scatter(x=[neuron_hard_limits[0], neuron_hard_limits[-1]], y=[1, 1], mode='lines', name='', line=dict(color='grey', dash='dash')))\n",
    "    for i, op in enumerate(OPERATORS):\n",
    "        traces.append(go.Scatter(x=neuron_hard_limits, y=ablated_results[i], mode='lines', name=f'{operator_labels[i]}',\n",
    "                                line=dict(color=colors[i])))\n",
    "        traces.append(go.Scatter(x=neuron_hard_limits, y=control_results[i], mode='lines', name=f'', showlegend=False,\n",
    "                                line=dict(color=colors[i], dash='dash')))\n",
    "    return traces\n",
    "\n",
    "\n",
    "def create_70b_figure():\n",
    "    model_name = 'llama3-70b'\n",
    "    neuron_hard_limits = torch.load(f'./data/{model_name}/addition_prompt_ablation_results_thres=0.6_HYBRID_maps.pt')[0]\n",
    "    lim = len(neuron_hard_limits) # //2 + 1 # UNCOMMENT FOR HALF X-AXIS (Same values as llama3-8b)\n",
    "    neuron_hard_limits = neuron_hard_limits[:lim]\n",
    "    traces = []\n",
    "    # traces.append(go.Scatter(x=[neuron_hard_limits[0], neuron_hard_limits[-1]], y=[1, 1], mode='lines', name='Baseline', line=dict(color='black'), showlegend=False))\n",
    "    for i, op in enumerate(operator_labels):\n",
    "        neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[i]}_prompt_ablation_results_thres=0.6_HYBRID_maps.pt')\n",
    "        neuron_hard_limits = list(neuron_hard_limits)[:lim]\n",
    "        baseline_results, ablated_results, ablated_neuron_counts, control_results = baseline_results[:lim], ablated_results[:lim], ablated_neuron_counts[:lim], control_results[:lim]\n",
    "        assert torch.all(baseline_results == 1)\n",
    "        traces.append(go.Scatter(x=neuron_hard_limits, y=ablated_results, mode='lines', name=f'{op}', line=dict(color=colors[i]), showlegend=False))\n",
    "        traces.append(go.Scatter(x=neuron_hard_limits, y=control_results, mode='lines', name=f'', line=dict(color=colors[i], dash='dash'), showlegend=False))\n",
    "    return traces\n",
    "\n",
    "\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, subplot_titles=(\"Llama3-8B\", \"Llama3-70B\"), horizontal_spacing=0.03)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Heuristic Ablation', line=dict(color='grey')))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Random Ablation', line=dict(dash='dash', color='grey')))\n",
    "\n",
    "# Add traces for llama3-8b\n",
    "for trace in create_8b_figure():\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "# Add traces for llama3-70b\n",
    "for trace in create_70b_figure():\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_yaxes(title=dict(text=\"Accuracy\", font=dict(size=17)), range=(0, 1.02), tickvals=[0.25, 0.5, 0.75, 1], tickfont=dict(size=15), row=1, col=1)\n",
    "fig.update_yaxes(range=(0, 1.02), tickvals=[0.25, 0.5, 0.75, 1], row=1, col=2)\n",
    "fig.update_xaxes(title=dict(standoff=0, text=f'Ablated Neurons (Per Layer)', font=dict(size=15)), tickvals=list(range(0, 81, 20)), tickfont=dict(size=15), row=1, col=1)\n",
    "fig.update_xaxes(title=dict(standoff=0, text=f'Ablated Neurons (Per Layer)', font=dict(size=15)), tickvals=list(range(0, 201, 40)), tickfont=dict(size=15), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title='',\n",
    "    margin=dict(l=0, r=0, t=20, b=83),\n",
    "    width=800,\n",
    "    height=250,\n",
    "    legend=dict(\n",
    "        font=dict(size=15),\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.45,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/llama3_8b_70b_prompt_knockout_per_layer.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness as function of head count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data for the figure\n",
    "\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "ie_maps = process_ie_maps(torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt'))\n",
    "max_n_heads = 100\n",
    "max_op = 300\n",
    "\n",
    "\n",
    "def build_circuit(operator_idx, n_heads):\n",
    "    heads = list(topk_effective_components(model, ie_maps[operator_idx], k=100, heads_only=True).keys())[:n_heads]\n",
    "    full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)]\n",
    "    full_circuit = Circuit(model.cfg)\n",
    "    for c in list(set(heads + full_mlps)):\n",
    "        full_circuit.add_component(c)\n",
    "    return full_circuit\n",
    "\n",
    "max_n_heads = 100\n",
    "seeds = [42, 412, 32879, 123, 436]\n",
    "faithfulness_results = torch.zeros((len(seeds), len(OPERATORS), max_n_heads))\n",
    "\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        set_deterministic(seed)\n",
    "        prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "        print(operator_idx, seed)\n",
    "\n",
    "        for n_heads in tqdm(range(0, max_n_heads)):\n",
    "            full_circuit = build_circuit(operator_idx, n_heads)\n",
    "            nl_acc = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "            faithfulness_results[seed_idx, operator_idx, n_heads] = nl_acc\n",
    "    \n",
    "        torch.save(faithfulness_results, f'./data/{model_name}/faithfulness_results_over_head_count_single_list.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the figure itself\n",
    "\n",
    "model_name = 'llama3-8b'\n",
    "max_n_heads = 100\n",
    "faithfulness_results = torch.load(f'./data/{model_name}/faithfulness_results_over_head_count.pt')\n",
    "print(faithfulness_results.shape)\n",
    "faithfulness_results = faithfulness_results.mean(dim=0)\n",
    "                         \n",
    "fig = multiple_lines(list(range(max_n_heads - 50)), faithfulness_results, ['+', '-', '', ''], show_fig=False, colors=COLORBLIND_COLORS)\n",
    "fig.update_yaxes(title=dict(text=\"Faithfulness\", font=dict(size=17), standoff=10), range=(0, 1.0), tickvals=[0.5, 1.0], tickfont=dict(size=16))\n",
    "fig.update_xaxes(title=dict(text=\"Number of heads in circuit\", font=dict(size=17), standoff=5), tickfont=dict(size=16))\n",
    "fig.update_layout(\n",
    "    legend=dict(itemwidth=30, orientation=\"h\", itemsizing='constant', \n",
    "                yanchor=\"bottom\", y=-0.5, xanchor=\"center\", x=0.5, font=dict(size=17)),\n",
    "    margin=dict(l=0, r=00, t=40, b=0), \n",
    "    width=400, height=250,\n",
    "    title=dict(\n",
    "        text=\"Llama3-8B circuit faithfulness<br>as function of number of circuit heads\",\n",
    "        x=0.58, y=0.94,\n",
    "        font=dict(size=17),\n",
    "        xanchor='center',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, fr'./figs/faithfulness_over_head_count.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding failure modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribs = torch.load(f'./data/{model_name}/correct_and_incorrect_prompts_heuristic_logit_contributions.pt')\n",
    "\n",
    "logit_contribs, incorrect_logit_contribs = contribs[OPERATORS[0]]\n",
    "\n",
    "correct_y = [logit_contribs[prompt].sum().item() for prompt in logit_contribs]\n",
    "incorrect_y = [incorrect_logit_contribs[prompt].sum().item() for prompt in incorrect_logit_contribs]\n",
    "\n",
    "correct_mean = np.mean(correct_y)\n",
    "incorrect_mean = np.mean(incorrect_y)\n",
    "correct_std = np.std(correct_y)\n",
    "incorrect_std = np.std(incorrect_y)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "    y0=0,\n",
    "    x=correct_y,\n",
    "    name=\"Correct\",\n",
    "    boxpoints='all',\n",
    "    jitter=0.3,\n",
    "    pointpos=-1.8,\n",
    "    marker_color='blue',\n",
    "    orientation='h',\n",
    "    boxmean=True,\n",
    "    whiskerwidth=0.1,\n",
    "    width=0.1,\n",
    "    marker=dict(size=5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "    y0=0.4,\n",
    "    x=incorrect_y,\n",
    "    name=\"Incorrect\",\n",
    "    boxpoints='all',\n",
    "    jitter=0.3,\n",
    "    marker_color='red',\n",
    "    orientation='h',\n",
    "    boxmean=True,\n",
    "    whiskerwidth=0.0,\n",
    "    width=0.1,\n",
    "    marker=dict(size=5),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=450,\n",
    "    height=100,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_xaxes(title=dict(standoff=5, text=\"Correct answer logit contribution\", font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.update_yaxes(tickvals=[0, 0.35], ticktext=[\"Correct\", \"Incorrect\"], title=dict(text=\"Prompt Type\", font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/correct_and_incorrect_prompts_heuristic_logit_contributions.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional circuit components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP0 neuron effect scatter plot\n",
    "\n",
    "colors = COLORBLIND_COLORS\n",
    "layer = 0\n",
    "positions = [1, 2, 3]\n",
    "mlp0_neuron_scores = sum(get_neuron_importance_scores(ranking_method=\"mean\", operator_idx=0, pos=pos)[0] for pos in positions) / len(positions)\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=list(range(len(mlp0_neuron_scores))), y=mlp0_neuron_scores, \n",
    "                                mode=\"markers\",\n",
    "                                marker=dict(size=5, color=colors[0]), name=\"+\", showlegend=True))\n",
    "    \n",
    "fig.update_yaxes(title='Intervention Effect', range=[-0.02, 0.1], tickfont=dict(size=15), title_font=dict(size=16), tickvals=[0, 0.05])\n",
    "fig.update_xaxes(title=f'Neuron Index', tickfont=dict(size=15), title_font=dict(size=16))\n",
    "fig.update_layout(\n",
    "    title=f'Individual MLP Neuron Intervention Effects',\n",
    "    title_x=0.55,\n",
    "    title_y=0.98,\n",
    "    width=400,\n",
    "    height=200,\n",
    "    title_font=dict(size=16),\n",
    "    margin=dict(l=0, r=0, t=20, b=0),\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/mlp_neuron_intervention_effects_layer_{layer}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-K Neuron eval in MLP0\n",
    "\n",
    "max_op = 300\n",
    "later_layers_k = int(model.cfg.d_mlp * 0.01) # How many neurons to include in the circuit in each middle- and late- layer?\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "k_values = torch.tensor(sorted(list(range(0, 1000, 10)) + list(range(1000, model.cfg.d_mlp, 100)) + [model.cfg.d_mlp]))\n",
    "seeds = [42, 412, 32879, 123]\n",
    "results_file_path = f'./data/{model_name}/mlp0_topk_neuron_faithfulness_evaluation_results.pt'\n",
    "if os.path.exists(results_file_path):\n",
    "    faithfulness_per_k = torch.load(results_file_path)\n",
    "else:\n",
    "    faithfulness_per_k = {}\n",
    "\n",
    "# GENERATE DATA\n",
    "for seed in seeds:\n",
    "    for operator_idx in range(len(OPERATORS)):\n",
    "        if (operator_idx, seed) in faithfulness_per_k:\n",
    "            print(f\"Found results file for {operator_idx=}, {seed=}\")\n",
    "            continue\n",
    "        set_deterministic(seed)\n",
    "        prompts_and_answers = random.sample(evaluation_prompts_and_answers[operator_idx], k=50)\n",
    "        mlppost_neuron_scores = get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=-1) # Ranking neurons according to Attribution patching\n",
    "\n",
    "        mlp0_important_positions = [1, 2, 3] # Op1, Operator, Op2. MLP0 isn't important in the last position nor in the BoS position.\n",
    "        mlp0_neuron_scores = sum(get_neuron_importance_scores(model, model_name, operator_idx=operator_idx, pos=pos)[0] for pos in mlp0_important_positions) / len(mlp0_important_positions)\n",
    "\n",
    "        def build_circuit(operator_idx, mlp_top_neurons):      \n",
    "            if operator_idx == 0:\n",
    "                # Addition\n",
    "                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 3), (5, 31), (14, 12), (15, 13), (16, 21)]]\n",
    "            elif operator_idx == 1:\n",
    "                # Subtraction\n",
    "                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (13, 21), (13, 22), (14, 12), (15, 13), (16, 21)]]\n",
    "            elif operator_idx == 2:\n",
    "                # Multiplication\n",
    "                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 30), (8, 15), (9, 26), (13, 18), (13, 21), (13, 22), \n",
    "                                                                        (14, 12), (14, 13), (15, 8), (15, 13), (15, 14), (15, 15), (16, 3), \n",
    "                                                                        (16, 21), (17, 24), (17, 26), (18, 16), (20, 2), (22, 1)]]\n",
    "            elif operator_idx == 3:\n",
    "                # Division\n",
    "                heads = [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 31), (15, 13), (15, 14), (16, 21), (18, 16)]]\n",
    "\n",
    "            partial_mlp_layers = list(range(get_model_consts(model_name).first_heuristics_layer, model.cfg.n_layers))\n",
    "            full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers) if l not in partial_mlp_layers]\n",
    "            partial_mlps = [Component('mlp_post', layer=l, neurons=mlp_top_neurons[l]) for l in partial_mlp_layers]    \n",
    "            partial_mlp0 = [Component('mlp_post', layer=0, neurons=mlp_top_neurons[0])]\n",
    "            full_circuit = Circuit(model.cfg)\n",
    "            for c in list(set(heads + full_mlps + partial_mlps + partial_mlp0)):\n",
    "                full_circuit.add_component(c)\n",
    "            return full_circuit\n",
    "\n",
    "        faithfulness_per_k[(operator_idx, seed)] = torch.zeros((len(k_values),))\n",
    "        for i, mlp0_k in enumerate(k_values):\n",
    "            mlp_top_neurons = {}\n",
    "            for mlp in range(1, model.cfg.n_layers):\n",
    "                mlp_top_neurons[mlp] = mlppost_neuron_scores[mlp].topk(later_layers_k).indices.tolist()\n",
    "            mlp_top_neurons[0] = mlp0_neuron_scores.topk(mlp0_k).indices.tolist()\n",
    "\n",
    "            full_circuit = build_circuit(operator_idx, mlp_top_neurons)\n",
    "            faithfulness_per_k[(operator_idx, seed)][i] = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "            print(mlp0_k, faithfulness_per_k[(operator_idx, seed)][i].item())\n",
    "        torch.save(faithfulness_per_k, results_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some activation patterns of important neurons in MLP0 to give a sense of what it does\n",
    "\n",
    "max_op = 300\n",
    "numerical_tokens = [str(i) for i in range(max_op)]\n",
    "activations = generate_activations(model, numerical_tokens, [Component('mlp_post', layer=0)], pos=-1)[0]\n",
    "\n",
    "layer = 0\n",
    "positions = [1, 2, 3] # Op1, Operator, Op2\n",
    "mlp0_neuron_scores = sum(get_neuron_importance_scores(ranking_method=\"mean+std\", operator_idx=0, pos=pos)[0] for pos in positions) / len(positions)\n",
    "neurons_to_vis = [6206, 7101, 8969] #mlp0_neuron_scores.topk(30).indices.tolist()\n",
    "for neuron in neurons_to_vis:\n",
    "    neuron_activations = activations[:, neuron]\n",
    "    scatter_with_labels(y=neuron_activations, title=f'Neuron {neuron} activations', x=numerical_tokens, hovertext=numerical_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the MLP0 top-k neurons eval figure\n",
    "\n",
    "k_values = torch.tensor(sorted(list(range(0, 1000, 10)) + list(range(1000, model.cfg.d_mlp, 100)) + [model.cfg.d_mlp]))\n",
    "seeds = [42, 412, 32879, 123]\n",
    "results_file_path = f'./data/{model_name}/mlp0_topk_neuron_faithfulness_evaluation_results.pt'\n",
    "visualization_ops = ['+', '-', '', '']\n",
    "colors = COLORBLIND_COLORS\n",
    "\n",
    "faithfulness_per_k = torch.load(results_file_path)\n",
    "# Average across seeds\n",
    "faithfulness_per_k = {operator_idx: torch.stack([faithfulness_per_k[(operator_idx, seed)] for seed in seeds]).mean(dim=0) for operator_idx in range(len(OPERATORS))}\n",
    "# Stack across operators\n",
    "faithfulness_per_k = torch.stack([faithfulness_per_k[operator_idx] for operator_idx in range(len(OPERATORS))])\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(len(OPERATORS)):\n",
    "    fig.add_trace(go.Scatter(x=k_values, y=faithfulness_per_k[i], mode='lines', name=visualization_ops[i], line=dict(color=colors[i])))\n",
    "\n",
    "x_axis_percentages = [0.01, 0.1, 1.0]\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        type=\"log\",\n",
    "        tickvals=[percent * model.cfg.d_mlp for percent in x_axis_percentages],\n",
    "        ticktext=[f\"{int(percent * 100)}%\" for percent in x_axis_percentages],\n",
    "        tickfont=dict(size=15),\n",
    "        title=\"Neurons used Per Layer (%)\",\n",
    "        title_font=dict(size=16),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Faithfulness\",\n",
    "        tickfont=dict(size=15),\n",
    "        title_font=dict(size=16),\n",
    "        range=(0.5, 1.0)\n",
    "    ),\n",
    "    legend=dict(itemwidth=30, itemsizing='constant', font=dict(size=16), bgcolor='rgba(0,0,0,0)', y=0.1),\n",
    "    title=\"Faithfulness of using only top-k neurons\",\n",
    "    title_x=0.55, title_y=0.98, title_font=dict(size=16), \n",
    "    margin=dict(l=0, r=0, t=20, b=0), \n",
    "    width=400, height=200, \n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/mlp0_faithfulness_topk_neurons.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw MLP0 neuron activation patterns\n",
    "\n",
    "# Generate MLP0 activations for numerical tokens\n",
    "max_op = 300\n",
    "numerical_tokens = [str(i) for i in range(max_op)]\n",
    "activations = generate_activations(model, numerical_tokens, [Component('mlp_post', layer=0)], pos=-1)[0]\n",
    "\n",
    "neurons_to_vis = [6206, 7101, 8969] # Manually found neurons to show several interesting patterns\n",
    "\n",
    "tickvals = {\n",
    "    6206: list(range(0, 301, 25)),\n",
    "    7101: list(range(0, 301, 25)),\n",
    "    8969: list(range(0, 301, 32))\n",
    "}\n",
    "\n",
    "colors = COLORBLIND_COLORS[1:]\n",
    "for neuron in neurons_to_vis:\n",
    "    neuron_activations = activations[:, neuron]\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(x=numerical_tokens, y=neuron_activations, \n",
    "                                mode=\"markers\",\n",
    "                                marker=dict(size=5, color=colors[0]), showlegend=False))\n",
    "    \n",
    "    fig.update_yaxes(title='Neuron activation', tickfont=dict(size=14), title_font=dict(size=16))\n",
    "    fig.update_xaxes(title=f'Numerical input token', tickfont=dict(size=14), title_font=dict(size=16), tickvals=tickvals[neuron])\n",
    "    fig.update_layout(\n",
    "        title_x=0.55,\n",
    "        title_y=0.98,\n",
    "        width=300,\n",
    "        height=200,\n",
    "        title_font=dict(size=16),\n",
    "        margin=dict(l=0, r=0, t=20, b=0),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    pio.write_image(fig, f'./figs/mlp0_neuron{neuron}_activations.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention head patterns\n",
    "\n",
    "operator_idx = 0\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    effective_heads = [\n",
    "        [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 3), (5, 31), (14, 12), (15, 13), (16, 21)]],\n",
    "        [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (13, 21), (13, 22), (14, 12), (15, 13), (16, 21)]],\n",
    "        [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 30), (8, 15), (9, 26), (13, 18), (13, 21), (13, 22), \n",
    "                                                        (14, 12), (14, 13), (15, 8), (15, 13), (15, 14), (15, 15), (16, 3), \n",
    "                                                        (16, 21), (17, 24), (17, 26), (18, 16), (20, 2), (22, 1)]],\n",
    "        [Component('z', layer=l, head=h) for (l, h) in [(2, 2), (5, 31), (15, 13), (15, 14), (16, 21), (18, 16)]]\n",
    "    ][operator_idx]\n",
    "    min_op = 1 if operator_idx == 3 else 0\n",
    "    prompts = generate_all_prompts_for_operator(OPERATORS[operator_idx], min_op, max_op, single_token_number_range=(0, LLAMA3_8B_CONSTS.max_single_token))\n",
    "    prompts = separate_prompts_and_answers(large_prompts_and_answers[operator_idx])[0]\n",
    "    head_html, head_patterns = visualize_arithmetic_attention_patterns(model, effective_heads, prompts, use_bos_token=True, return_raw_patterns=True)\n",
    "    torch.save((head_html, effective_heads, head_patterns), f'./data/{model_name}/mean_attn_head_patterns_{OPERATOR_NAMES[operator_idx]}.pt')\n",
    "    display(head_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention heads for paper\n",
    "\n",
    "attention_patterns, operator_counts = {}, {}\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    _, effective_heads, head_patterns = torch.load(f'./data/{model_name}/mean_attn_head_patterns_{OPERATOR_NAMES[operator_idx]}.pt')\n",
    "    for head, pattern in zip(effective_heads, head_patterns):\n",
    "        if (head.layer, head.head_idx) not in attention_patterns:\n",
    "            attention_patterns[(head.layer, head.head_idx)] = torch.zeros(4, 5, 5)\n",
    "            operator_counts[(head.layer, head.head_idx)] = 0\n",
    "        attention_patterns[(head.layer, head.head_idx)][operator_idx] = pattern\n",
    "        operator_counts[(head.layer, head.head_idx)] += 1\n",
    "\n",
    "important_heads = [(16, 21), (15, 13), (2, 2)]\n",
    "other_heads = list(set(attention_patterns.keys()) - set(important_heads))\n",
    "\n",
    "\n",
    "tickvals = [\"BoS\", \"Op1\", \"Operator\", \"Op2\", \"=\"]\n",
    "op_to_vis = None\n",
    "heads_to_vis = important_heads\n",
    "for head in heads_to_vis:\n",
    "    pattern = attention_patterns[head]\n",
    "    if op_to_vis is None:\n",
    "        pattern = pattern.sum(dim=0) / operator_counts[head]\n",
    "    else:\n",
    "        pattern = pattern[op_to_vis]\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=pattern,\n",
    "        x=tickvals,\n",
    "        y=tickvals,\n",
    "        colorscale='Purples',\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=False,\n",
    "        colorbar=dict(title='Value')\n",
    "    ))\n",
    "\n",
    "    # Add visible edges between pixels\n",
    "    for i in range(6):\n",
    "        fig.add_shape(type=\"line\",\n",
    "                    x0=-0.5, y0=i-0.5, x1=4.5, y1=i-0.5,\n",
    "                    line=dict(color=\"lightgrey\", width=1))\n",
    "        fig.add_shape(type=\"line\",\n",
    "                    x0=i-0.5, y0=-0.5, x1=i-0.5, y1=4.5,\n",
    "                    line=dict(color=\"lightgrey\", width=1))\n",
    "\n",
    "    fig.update_layout(width=300, height=300, coloraxis_showscale=False, margin=dict(l=0, r=0, t=0, b=0))\n",
    "    fig.update_yaxes(autorange=\"reversed\", tickfont=dict(size=17), title=dict(text=\"Destination Token\",  font=dict(size=18), standoff=10))\n",
    "    fig.update_xaxes(tickfont=dict(size=17), title=dict(text=\"Source Token\", font=dict(size=18), standoff=5))\n",
    "    fig.show()\n",
    "\n",
    "    pio.write_image(fig, f'./figs/attention_pattern_L{head[0]}H{head[1]}_{op_to_vis if op_to_vis else \"mean\"}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other appendices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many neurons get succesfully clasiffied by the algorithm?\n",
    "\n",
    "MATCH_THRESHOLD = 0.6\n",
    "\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    gt_heuristic_classes = load_heuristic_classes(f\"./data/{model_name}\", operator_idx, \"HYBRID\")\n",
    "    pre_filter_heuristic_neurons = set([(v[0], v[1]) for v in chain.from_iterable(gt_heuristic_classes.values())])\n",
    "    \n",
    "    # Filter by threshold\n",
    "    gt_heuristic_classes = {name: [(l, n, s) for (l, n, s) in layer_neuron_scores if s >= MATCH_THRESHOLD] for name, layer_neuron_scores in gt_heuristic_classes.items()}\n",
    "    gt_heuristic_classes = {name: lns for name, lns in gt_heuristic_classes.items() if len(lns) > 0}\n",
    "    post_filter_heuristic_neurons = set([(v[0], v[1]) for v in chain.from_iterable(gt_heuristic_classes.values())])\n",
    "\n",
    "    print(operator_idx, f\"{len(post_filter_heuristic_neurons)} / {len(pre_filter_heuristic_neurons)} = {len(post_filter_heuristic_neurons) / len(pre_filter_heuristic_neurons)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show neuron intersection across operators\n",
    "\n",
    "k_per_layer = 200\n",
    "model_consts = LLAMA3_8B_CONSTS\n",
    "layers = list(range(model_consts.first_heuristics_layer, model.cfg.n_layers))\n",
    "\n",
    "mlp_neurons_per_operator = {}\n",
    "for op_idx in range(len(OPERATORS)):\n",
    "    mlp_neurons_per_operator[op_idx] = []\n",
    "    top_neurons = get_neuron_importance_scores(operator_idx=op_idx)\n",
    "    for layer in layers:\n",
    "        top_neurons_in_layer = top_neurons[layer].topk(k=k_per_layer).indices.tolist()\n",
    "        mlp_neurons_per_operator[op_idx] += [(layer, neuron) for neuron in top_neurons_in_layer]\n",
    "    \n",
    "# Plot the intersection between operators\n",
    "intersection_neurons = [[round(len(set(mlp_neurons_per_operator[i]).intersection(set(mlp_neurons_per_operator[j]))) / len(set(mlp_neurons_per_operator[i]).union(set(mlp_neurons_per_operator[j]))), 3) for j in range(len(OPERATORS))] for i in range(len(OPERATORS))]\n",
    "\n",
    "# Plot heatmap with labels\n",
    "vis_operators = ['+', '-', '', '']\n",
    "fig = px.imshow(intersection_neurons, \n",
    "                x=vis_operators, y=vis_operators, text_auto='.1%',\n",
    "                width=370, height=370,\n",
    "                color_continuous_midpoint=0.6, color_continuous_scale='Blues')\n",
    "fig.update_traces(textfont_size=16)\n",
    "fig.update_xaxes(title=dict(text='Operator', standoff=10), title_font=dict(size=17), tickfont=dict(size=17))\n",
    "fig.update_yaxes(title=dict(text='Operator', standoff=10), title_font=dict(size=17), tickfont=dict(size=17))\n",
    "fig.update_coloraxes(colorbar_len=0.7, colorbar_thickness=15)\n",
    "fig.update_layout(title='Neuron Intersection Across Operators', title_font=dict(size=17), title_x=0.5, title_y=0.92, margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/neuron_intersection_across_operators.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model accuracy\n",
    "\n",
    "models = ['gptj', 'llama3-70b', 'pythia-6.9b-step143000', 'llama3-8b']\n",
    "for m in models:\n",
    "    acc = torch.load(f'./data/{m}/accuracy.pt')\n",
    "    min_op, max_op = 0, 300\n",
    "    print(m, acc)\n",
    "    \n",
    "    with open(f'./data/{m}/large_prompts_and_answers_max_op=300.pkl', 'rb') as f:\n",
    "        large_prompts_and_answers = pickle.load(f)\n",
    "    print([len([pa for pa in large_prompts_and_answers[op_idx] if int(pa[1]) > 0]) / len(generate_all_prompts_for_operator(OPERATORS[op_idx], min_op, max_op)) for op_idx in range(4)])\n",
    "\n",
    "    total_valid_prompts = sum([len(generate_all_prompts_for_operator(OPERATORS[op_idx], min_op, max_op)) for op_idx in range(4)])\n",
    "    total_correct_prompts = sum([acc[OPERATORS[op_idx]] * len(generate_all_prompts_for_operator(OPERATORS[op_idx], min_op, max_op)) for op_idx in range(4)])\n",
    "    print(\"Overall\", total_correct_prompts / total_valid_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results for \"other models\" appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the faithfulness of other models\n",
    "\n",
    "model_name, model_path = 'gptj', 'gptj'\n",
    "\n",
    "max_op = 300\n",
    "mean_cache = torch.load(f'./data/{model_name}/mean_cache_for_evaluation_all_arithmetic_prompts_max_op={max_op}.pt')\n",
    "if mean_cache[list(mean_cache.keys())[0]].shape[0] != 50:\n",
    "    mean_cache = {c: a.repeat(50, 1, 1) for c, a in mean_cache.items()}\n",
    "\n",
    "if 'model' not in locals():\n",
    "    model = load_model(model_name, model_path, \"cuda\", extra_hooks=True)\n",
    "\n",
    "with open(fr'./data/{model_name}/large_prompts_and_answers_max_op={max_op}.pkl', 'rb') as f:\n",
    "    large_prompts_and_answers = pickle.load(f)\n",
    "    large_prompts_and_answers = [[pa for pa in large_prompts_and_answers[op_idx] if pa[1] != '0'] for op_idx in range(4)]\n",
    "\n",
    "def build_circuit(model, model_name, operator_idx):\n",
    "    heads = topk_effective_components(model, ie_maps, k=50, heads_only=True).keys()\n",
    "    partial_mlp_layers = list(range(get_model_consts(model_name).first_heuristics_layer, model.cfg.n_layers))\n",
    "    full_mlps = [Component('mlp_post', layer=l) for l in range(model.cfg.n_layers)] if l not in partial_mlp_layers]\n",
    "    partial_mlps = [Component('mlp_post', layer=l, neurons=mlp_top_neurons[l]) for l in partial_mlp_layers]\n",
    "\n",
    "    full_circuit = Circuit(model.cfg)\n",
    "    for c in list(set(heads + full_mlps + partial_mlps)):\n",
    "        full_circuit.add_component(c)\n",
    "    return full_circuit\n",
    "\n",
    "seeds = [42, 412, 32879, 123, 436]\n",
    "for operator_idx in range(len(OPERATORS)):\n",
    "    ie_maps = torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt')\n",
    "    summed_seed_ie_maps = {}\n",
    "    for op_idx, pos, seed in ie_maps.keys():\n",
    "        if (op_idx, pos) not in summed_seed_ie_maps:\n",
    "            summed_seed_ie_maps[(op_idx, pos)] = ie_maps[(op_idx, pos, seed)]\n",
    "        else:\n",
    "            summed_seed_ie_maps[(op_idx, pos)] += ie_maps[(op_idx, pos, seed)]\n",
    "    ie_maps = {k: v / len(seeds) for (k, v) in summed_seed_ie_maps.items()}\n",
    "    ie_maps = torch.stack([ie_maps[(operator_idx, pos)] for pos in POSITIONS]).mean(dim=0) # Average across positions\n",
    "\n",
    "    avg_nl_acc = 0\n",
    "    for seed in seeds:\n",
    "        set_deterministic(seed)\n",
    "        prompts_and_answers = random.sample(large_prompts_and_answers[operator_idx], k=50)\n",
    "        full_circuit = build_circuit(model, model_name, operator_idx)\n",
    "        nl_acc = circuit_faithfulness_with_mean_ablation(model, full_circuit, prompts_and_answers, mean_cache, metric='nl')\n",
    "        avg_nl_acc += nl_acc\n",
    "        print(f\"Normalized Logit Acc (Seed {seed}): {nl_acc:.3f}\")\n",
    "\n",
    "    avg_nl_acc = avg_nl_acc / len(seeds)\n",
    "    print(f\"Avg Normalized Logit Acc: {avg_nl_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCALIZATION\n",
    "\n",
    "model_name = \"gptj\"\n",
    "# model_name = \"pythia-6.9b-step143000\"\n",
    "# model_name = \"llama3-70b\"\n",
    "attn_maps_sum_over_positions = False # If False, only the last position IE is presented\n",
    "\n",
    "ie_maps = torch.load(f'./data/{model_name}/ie_maps_activation_patching.pt')\n",
    "\n",
    "# Average across seeds\n",
    "summed_seed_ie_maps = {}\n",
    "seeds = [42, 412, 32879, 123, 436] if model_name != 'llama3-70b' else [42] # Could only run one seed due to GPU requirements\n",
    "for op_idx, pos, seed in ie_maps.keys():\n",
    "    if (op_idx, pos) not in summed_seed_ie_maps:\n",
    "        summed_seed_ie_maps[(op_idx, pos)] = ie_maps[(op_idx, pos, seed)]\n",
    "    else:\n",
    "        summed_seed_ie_maps[(op_idx, pos)] += ie_maps[(op_idx, pos, seed)]\n",
    "ie_maps = {k: v / len(seeds) for (k, v) in summed_seed_ie_maps.items()}\n",
    "# Average across operators\n",
    "ie_maps = {pos: torch.stack([ie_maps[(op_idx, pos)] for op_idx in range(len(OPERATORS))]).mean(dim=0) for pos in POSITIONS}\n",
    "# Tensorify\n",
    "ie_maps = torch.stack([ie_maps[pos] for pos in POSITIONS]) # pos, Layers, heads+mlp\n",
    "ie_maps = np.log1p(ie_maps)\n",
    "attn_maps, mlp_maps = ie_maps[:, :, :-1], ie_maps[:, :, -1]\n",
    "if attn_maps_sum_over_positions:\n",
    "    attn_maps = attn_maps.sum(dim=0) # Sum effect from all positions\n",
    "else:\n",
    "    attn_maps = attn_maps[-1] # Take only last position\n",
    "mlp_maps = mlp_maps.T\n",
    "\n",
    "\n",
    "# Find the global min and max values\n",
    "global_min = min(attn_maps.min(), mlp_maps.min()).item()\n",
    "global_max = max(attn_maps.max(), mlp_maps.max()).item()\n",
    "\n",
    "# Create subplots\n",
    "attn_title = \"Attention Heads (Summed over positions)\" if attn_maps_sum_over_positions else \"Attention Heads (Last Position)\"\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[attn_title, \"MLPs\"], shared_yaxes=True)\n",
    "\n",
    "# Add heatmaps to subplots\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=attn_maps,\n",
    "        coloraxis=\"coloraxis\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(z=mlp_maps, coloraxis=\"coloraxis\"),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=dict(text=\"Attention Head\", font=dict(size=16), standoff=8), tickfont=dict(size=15), domain=[0, 0.7], row=1, col=1)\n",
    "fig.update_yaxes(title=dict(text=\"Layer\", font=dict(size=16), standoff=15), tickfont=dict(size=15), autorange=\"reversed\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title=dict(text=\"Position\", font=dict(size=16), standoff=8), tickfont=dict(size=15), domain=[0.8, 1.0], row=1, col=2)\n",
    "fig.update_yaxes(autorange=\"reversed\", row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Effect Map Per Attn Head / MLP\",\n",
    "        'x': 0.55, 'y': 0.98,\n",
    "        'font': dict(size=17)\n",
    "    },\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    "    height=250,\n",
    "    width=500,\n",
    "    coloraxis=dict(\n",
    "        colorscale='Blues',\n",
    "        cmin=global_min,\n",
    "        cmax=global_max,\n",
    "        colorbar=dict(\n",
    "            title=dict(text=\"log<br>scale\", font=dict(size=17)),\n",
    "            tickfont=dict(size=15),\n",
    "            thickness=20,\n",
    "            len=1.5,\n",
    "            yanchor=\"middle\",\n",
    "            y=0.65,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.layout.annotations[0].update(x=0.34, y=1.01, font=dict(size=16))\n",
    "fig.layout.annotations[1].update(x=0.90, y=1.01, font=dict(size=16))\n",
    "\n",
    "\n",
    "pio.write_image(fig, f'./figs/{model_name}_localization.png')\n",
    "pio.write_image(fig, f'./figs/{model_name}_localization.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION (TOP-K NEURONS)\n",
    "\n",
    "# model_name = \"gptj\"\n",
    "# model_name = \"pythia-6.9b-step143000\"\n",
    "model_name = \"llama3-70b\"\n",
    "\n",
    "operator_labels = ['+', '-', '', '']\n",
    "colors = COLORBLIND_COLORS\n",
    "d_mlp = 16384 if model_name in ['gptj', 'pythia-6.9b-step143000'] else 28672 # To avoid loading Llama3-70b just for this hardcoded number\n",
    "\n",
    "\n",
    "k_values = torch.tensor(sorted(list(range(0, 500, 10)) + list(range(500, d_mlp, 50)) + [d_mlp]))\n",
    "seeds = [42, 412, 32879]\n",
    "results_file_path = f'./data/{model_name}/topk_neuron_faithfulness_evaluation_results.pt'\n",
    "\n",
    "faithfulness_per_k = torch.load(results_file_path)\n",
    "faithfulness_per_k = {operator_idx: torch.stack([faithfulness_per_k[(operator_idx, seed)] for seed in seeds]).mean(dim=0) for operator_idx in range(len(OPERATORS))} # Average across seeds\n",
    "faithfulness_per_k = torch.stack([faithfulness_per_k[operator_idx] for operator_idx in range(len(OPERATORS))]) # Stack across operators\n",
    "\n",
    "fig = go.Figure()\n",
    "for op_idx in range(len(OPERATORS)):\n",
    "    fig.add_trace(go.Scatter(x=k_values, y=faithfulness_per_k[op_idx], mode='lines', name=operator_labels[op_idx], line=dict(color=colors[op_idx])))\n",
    "\n",
    "x_axis_percentages = [0.01, 0.1, 1]\n",
    "fig.update_xaxes(title=dict(text=\"Neurons used Per Layer\", font=dict(size=17), standoff=5), tickfont=dict(size=16))\n",
    "fig.update_yaxes(title=dict(text=\"Faithfulness\", font=dict(size=17), standoff=10), range=(0, 1.0), tickvals=[0.2, 0.4, 0.6, 0.8], tickfont=dict(size=16))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        type=\"log\",\n",
    "        tickvals=[percent * d_mlp for percent in x_axis_percentages],\n",
    "        ticktext=[f\"{int(percent * 100)}%\" for percent in x_axis_percentages],\n",
    "        title=dict(text=\"Neurons used Per Layer (%)\", font=dict(size=17), standoff=5)\n",
    "    ),\n",
    "    legend=dict(itemwidth=30, orientation=\"h\", itemsizing='constant', yanchor=\"bottom\", \n",
    "                y=-0.4, xanchor=\"center\", x=0.5, font=dict(size=17)),\n",
    "    title=dict(text=\"Faithfulness of using only top-k neurons\", x=0.56, y=0.98, font=dict(size=17)),\n",
    "    margin=dict(l=0, r=0, t=20, b=0), \n",
    "    width=400, height=250, \n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/{model_name}_faithfulness_topk_neurons.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing\n",
    "\n",
    "# model_name = \"pythia-6.9b-step143000\"\n",
    "model_name = \"gptj\"\n",
    "# model_name = \"llama3-70b\"\n",
    "probe_accs = torch.load(f'./data/{model_name}/probe_accs.pt')\n",
    "\n",
    "# Average across operators\n",
    "probe_accs = {pos_to_probe: torch.tensor([probe_accs[(operator_idx, pos_to_probe)] for operator_idx in range(len(OPERATORS))]).mean(dim=0) for pos_to_probe in POSITIONS}\n",
    "\n",
    "# Tensorify\n",
    "probe_accs_tensor = torch.stack([probe_accs[pos_to_probe] for pos_to_probe in POSITIONS])\n",
    "\n",
    "probe_accs_tensor = probe_accs_tensor.T # For nicer visualization\n",
    "\n",
    "fig = px.imshow(probe_accs_tensor, \n",
    "       x=['Operand1', 'Operator', 'Operand2', '='],\n",
    "       y=list(range(probe_accs_tensor.shape[0])),\n",
    "       width=250,\n",
    "       height=250,\n",
    "       zmin=0,\n",
    "       color_continuous_midpoint=0.0, color_continuous_scale=\"blues\"\n",
    ")\n",
    "fig.update_yaxes(title=dict(text=\"Layer\", standoff=15, font=dict(size=17)), tickvals=list(range(0, probe_accs_tensor.shape[0], probe_accs_tensor.shape[0] // 4)), tickfont=dict(size=15))\n",
    "fig.update_xaxes(title=dict(text=\"Position\", standoff=10, font=dict(size=17)), tickfont=dict(size=15))\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=50, b=0),\n",
    "                  title=dict(x=0.47, y=0.95, text=\"Answer token<br>probe accuracy\", font=dict(size=17)))\n",
    "fig.update_coloraxes(colorbar=dict(len=1.1,\n",
    "                                   thickness=20,\n",
    "                                   yanchor=\"middle\",\n",
    "                                   y=0.5))\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'./figs/{model_name}_probing_acc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt knockout \n",
    "\n",
    "# model_name = \"pythia-6.9b-step143000\"\n",
    "model_name = \"gptj\"\n",
    "# model_name = \"llama3-70b\"\n",
    "\n",
    "HEURISTIC_MATCH_THRESHOLD = 0.6\n",
    "operator_labels = ['+', '-', '', '']\n",
    "colors = COLORBLIND_COLORS\n",
    "\n",
    "neuron_hard_limits = torch.load(f'./data/{model_name}/addition_prompt_ablation_results_thres={HEURISTIC_MATCH_THRESHOLD}_HYBRID_maps.pt')[0]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Heuristic Ablation', line=dict(color='grey')))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Random Ablation', line=dict(dash='dash', color='grey')))\n",
    "\n",
    "for i, op in enumerate(OPERATORS):\n",
    "    neuron_hard_limits, baseline_results, ablated_results, ablated_neuron_counts, control_results = torch.load(f'./data/{model_name}/{OPERATOR_NAMES[i]}_prompt_ablation_results_thres={HEURISTIC_MATCH_THREHSOLD}_HYBRID_maps.pt')\n",
    "    neuron_hard_limits = list(neuron_hard_limits)\n",
    "    assert torch.all(baseline_results == 1)\n",
    "    fig.add_trace(go.Scatter(x=neuron_hard_limits, y=ablated_results, mode='lines', name=f'{operator_labels[i]}',\n",
    "                            line=dict(color=colors[i])))\n",
    "    fig.add_trace(go.Scatter(x=neuron_hard_limits, y=control_results, mode='lines', name=f'', showlegend=False,\n",
    "                            line=dict(color=colors[i], dash='dash')))\n",
    "\n",
    "fig.update_yaxes(title=dict(text=\"Accuracy\", font=dict(size=17)), range=(0, 1.02), tickvals=[0.25, 0.5, 0.75, 1], tickfont=dict(size=15))\n",
    "fig.update_xaxes(title=dict(standoff=0, text=f'Ablated Neurons (Per Layer)', font=dict(size=17)), tickvals=list(range(0, 81, 20)), tickfont=dict(size=15))\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        font=dict(size=15),\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.95,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=20, b=80), \n",
    "    width=400,\n",
    "    height=350,\n",
    "    title=dict(\n",
    "        text=\"Heuristic knockout accuracies\",\n",
    "        x=0.5,\n",
    "        y=0.98,\n",
    "        font=dict(size=16),\n",
    "        xanchor='center',\n",
    "        yanchor='top'\n",
    "    ),\n",
    ")\n",
    "fig.show()\n",
    "pio.write_image(fig, f'./figs/{model_name}_prompt_knockout_per_layer.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
